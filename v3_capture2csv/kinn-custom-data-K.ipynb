{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGUgpF_54cvP",
    "outputId": "0a10fc0d-8c96-4b91-849c-1fb7caa3fbe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pyod\n",
      "  Downloading pyod-2.0.3.tar.gz (169 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyod) (1.3.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyod) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyod) (1.24.3)\n",
      "Collecting numba>=0.51 (from pyod)\n",
      "  Downloading numba-0.60.0-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: scipy>=1.5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyod) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyod) (1.2.2)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51->pyod)\n",
      "  Downloading llvmlite-0.43.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.22.0->pyod) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->pyod) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->pyod) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->pyod) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->pyod) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->pyod) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->pyod) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->pyod) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->pyod) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->pyod) (1.16.0)\n",
      "Downloading numba-0.60.0-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 1.3/2.7 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 8.2 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.43.0-cp311-cp311-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.6/28.1 MB 8.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.7/28.1 MB 9.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 5.5/28.1 MB 9.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 7.6/28.1 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 9.7/28.1 MB 9.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 11.0/28.1 MB 9.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 13.4/28.1 MB 9.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 15.2/28.1 MB 9.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 16.8/28.1 MB 9.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 18.4/28.1 MB 9.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 19.9/28.1 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 21.8/28.1 MB 8.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.3/28.1 MB 8.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 25.2/28.1 MB 8.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.7/28.1 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 8.7 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: pyod\n",
      "  Building wheel for pyod (setup.py): started\n",
      "  Building wheel for pyod (setup.py): finished with status 'done'\n",
      "  Created wheel for pyod: filename=pyod-2.0.3-py3-none-any.whl size=200537 sha256=71722aec064a18e3e37cd9bb92f103a8fff2a66f882311f7fbfe357996b7c8c0\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\2d\\60\\5b\\f74eccd2c9c892a2c298202ca510f10995f9940647fcc2d97f\n",
      "Successfully built pyod\n",
      "Installing collected packages: llvmlite, numba, pyod\n",
      "Successfully installed llvmlite-0.43.0 numba-0.60.0 pyod-2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, MinMaxScaler, Normalizer, RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import keras\n",
    "\n",
    "#from keras.utils.np_utils import to_categorical\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import urllib.request\n",
    "import shutil\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "from typing import List, Tuple, Generator, Iterator\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "# %pip install pyod\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.inne import INNE\n",
    "# import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL4r6ensYSYp"
   },
   "source": [
    "###### **Preprocessing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "TeARnBrHX12x",
    "outputId": "f912cdaa-bbd8-4750-f1f5-b69bc17098ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>flow_byte</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Srate</th>\n",
       "      <th>Drate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>psh_flag_number</th>\n",
       "      <th>ack_flag_number</th>\n",
       "      <th>urg_flag_number</th>\n",
       "      <th>ece_flag_number</th>\n",
       "      <th>cwr_flag_number</th>\n",
       "      <th>ack_count</th>\n",
       "      <th>syn_count</th>\n",
       "      <th>fin_count</th>\n",
       "      <th>urg_count</th>\n",
       "      <th>rst_count</th>\n",
       "      <th>CoAP</th>\n",
       "      <th>HTTP</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DNS</th>\n",
       "      <th>Telnet</th>\n",
       "      <th>SMTP</th>\n",
       "      <th>SSH</th>\n",
       "      <th>IRC</th>\n",
       "      <th>TCP</th>\n",
       "      <th>UDP</th>\n",
       "      <th>DHCP</th>\n",
       "      <th>ARP</th>\n",
       "      <th>ICMP</th>\n",
       "      <th>IGMP</th>\n",
       "      <th>IPv</th>\n",
       "      <th>LLC</th>\n",
       "      <th>Tot sum</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>AVG</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Magnitue</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Covariance</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Weight</th>\n",
       "      <th>DS status</th>\n",
       "      <th>Fragments</th>\n",
       "      <th>Sequence number</th>\n",
       "      <th>flow_idle_time</th>\n",
       "      <th>flow_active_time</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000193</td>\n",
       "      <td>832</td>\n",
       "      <td>80</td>\n",
       "      <td>61786</td>\n",
       "      <td>64</td>\n",
       "      <td>10369.107540</td>\n",
       "      <td>10369.107540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1501</td>\n",
       "      <td>54</td>\n",
       "      <td>778</td>\n",
       "      <td>187.625000</td>\n",
       "      <td>234.260505</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>8</td>\n",
       "      <td>19.371371</td>\n",
       "      <td>321.382074</td>\n",
       "      <td>-14259.875000</td>\n",
       "      <td>11.639548</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.928810e-04</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.298898</td>\n",
       "      <td>7558</td>\n",
       "      <td>443</td>\n",
       "      <td>35442</td>\n",
       "      <td>55</td>\n",
       "      <td>11.548251</td>\n",
       "      <td>11.548251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4151</td>\n",
       "      <td>54</td>\n",
       "      <td>1506</td>\n",
       "      <td>319.307692</td>\n",
       "      <td>502.889709</td>\n",
       "      <td>1506</td>\n",
       "      <td>0.582391</td>\n",
       "      <td>13</td>\n",
       "      <td>25.182335</td>\n",
       "      <td>710.282604</td>\n",
       "      <td>-190.050000</td>\n",
       "      <td>1.019383</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.030751e-01</td>\n",
       "      <td>1.298898</td>\n",
       "      <td>0_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.308947</td>\n",
       "      <td>21437</td>\n",
       "      <td>443</td>\n",
       "      <td>35442</td>\n",
       "      <td>55</td>\n",
       "      <td>22.155212</td>\n",
       "      <td>22.155212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5942</td>\n",
       "      <td>54</td>\n",
       "      <td>1506</td>\n",
       "      <td>848.857143</td>\n",
       "      <td>692.984318</td>\n",
       "      <td>1506</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>7</td>\n",
       "      <td>38.716921</td>\n",
       "      <td>105.655099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.320840e-04</td>\n",
       "      <td>1.308947</td>\n",
       "      <td>0_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.427035</td>\n",
       "      <td>1477</td>\n",
       "      <td>35441</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>5.606030</td>\n",
       "      <td>5.606030</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6391</td>\n",
       "      <td>54</td>\n",
       "      <td>1506</td>\n",
       "      <td>532.583333</td>\n",
       "      <td>649.853376</td>\n",
       "      <td>54</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>12</td>\n",
       "      <td>35.448554</td>\n",
       "      <td>493.924529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.267583e+00</td>\n",
       "      <td>1.427035</td>\n",
       "      <td>0_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.480285</td>\n",
       "      <td>1585</td>\n",
       "      <td>35441</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>6.755456</td>\n",
       "      <td>6.755456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6553</td>\n",
       "      <td>54</td>\n",
       "      <td>1506</td>\n",
       "      <td>436.866667</td>\n",
       "      <td>611.959352</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>15</td>\n",
       "      <td>30.470126</td>\n",
       "      <td>665.957497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.359980e-04</td>\n",
       "      <td>1.480285</td>\n",
       "      <td>0_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115067</th>\n",
       "      <td>0.002669</td>\n",
       "      <td>280</td>\n",
       "      <td>44216</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>1498.634748</td>\n",
       "      <td>1498.634748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1</td>\n",
       "      <td>8.124038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.100000e-05</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115068</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>86</td>\n",
       "      <td>53608</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "      <td>1498.634748</td>\n",
       "      <td>1498.634748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>66</td>\n",
       "      <td>86</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>86</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>2</td>\n",
       "      <td>8.717798</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.716628e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115069</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>86</td>\n",
       "      <td>40828</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "      <td>43.190489</td>\n",
       "      <td>43.190489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1460</td>\n",
       "      <td>60</td>\n",
       "      <td>436</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>144.706600</td>\n",
       "      <td>86</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>10</td>\n",
       "      <td>15.099669</td>\n",
       "      <td>150.421630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.716628e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115070</th>\n",
       "      <td>0.001351</td>\n",
       "      <td>280</td>\n",
       "      <td>44246</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>2961.033533</td>\n",
       "      <td>2961.033533</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2192</td>\n",
       "      <td>60</td>\n",
       "      <td>436</td>\n",
       "      <td>199.272727</td>\n",
       "      <td>155.298007</td>\n",
       "      <td>66</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>11</td>\n",
       "      <td>16.905620</td>\n",
       "      <td>157.489555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.990000e-05</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115071</th>\n",
       "      <td>0.715423</td>\n",
       "      <td>5058</td>\n",
       "      <td>49126</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>16.773291</td>\n",
       "      <td>16.773291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3861</td>\n",
       "      <td>60</td>\n",
       "      <td>446</td>\n",
       "      <td>227.117647</td>\n",
       "      <td>162.810927</td>\n",
       "      <td>444</td>\n",
       "      <td>0.102268</td>\n",
       "      <td>17</td>\n",
       "      <td>18.665476</td>\n",
       "      <td>169.177737</td>\n",
       "      <td>-653.066667</td>\n",
       "      <td>28.782629</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.022680e-01</td>\n",
       "      <td>0.715423</td>\n",
       "      <td>0_normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115072 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        flow_duration  flow_byte  src_port  dst_port  Duration          Rate  \\\n",
       "0            0.000193        832        80     61786        64  10369.107540   \n",
       "1            1.298898       7558       443     35442        55     11.548251   \n",
       "2            1.308947      21437       443     35442        55     22.155212   \n",
       "3            1.427035       1477     35441        80       128      5.606030   \n",
       "4            1.480285       1585     35441        80       128      6.755456   \n",
       "...               ...        ...       ...       ...       ...           ...   \n",
       "115067       0.002669        280     44216        80        64   1498.634748   \n",
       "115068       0.000000         86     53608        53        64   1498.634748   \n",
       "115069       0.000000         86     40828        53        64     43.190489   \n",
       "115070       0.001351        280     44246        80        64   2961.033533   \n",
       "115071       0.715423       5058     49126      1900         2     16.773291   \n",
       "\n",
       "               Srate  Drate  fin_flag_number  syn_flag_number  \\\n",
       "0       10369.107540      0                0                0   \n",
       "1          11.548251      0                0                0   \n",
       "2          22.155212      0                0                0   \n",
       "3           5.606030      0                1                0   \n",
       "4           6.755456      0                0                0   \n",
       "...              ...    ...              ...              ...   \n",
       "115067   1498.634748      0                0                0   \n",
       "115068   1498.634748      0                0                0   \n",
       "115069     43.190489      0                0                0   \n",
       "115070   2961.033533      0                0                0   \n",
       "115071     16.773291      0                0                0   \n",
       "\n",
       "        rst_flag_number  psh_flag_number  ack_flag_number  urg_flag_number  \\\n",
       "0                     0                0                1                0   \n",
       "1                     0                0                1                0   \n",
       "2                     0                0                1                0   \n",
       "3                     0                0                1                0   \n",
       "4                     0                0                1                0   \n",
       "...                 ...              ...              ...              ...   \n",
       "115067                1                0                1                0   \n",
       "115068                0                0                0                0   \n",
       "115069                0                0                0                0   \n",
       "115070                1                0                1                0   \n",
       "115071                0                0                0                0   \n",
       "\n",
       "        ece_flag_number  cwr_flag_number  ack_count  syn_count  fin_count  \\\n",
       "0                     0                0          0          0          0   \n",
       "1                     0                0          0          2          0   \n",
       "2                     0                0          0          2          0   \n",
       "3                     0                0          1          2          0   \n",
       "4                     0                0          2          2          0   \n",
       "...                 ...              ...        ...        ...        ...   \n",
       "115067                0                0          0          2          1   \n",
       "115068                0                0          0          0          0   \n",
       "115069                0                0          0          0          0   \n",
       "115070                0                0          0          2          1   \n",
       "115071                0                0          0          0          0   \n",
       "\n",
       "        urg_count  rst_count  CoAP  HTTP  HTTPS  DNS  Telnet  SMTP  SSH  IRC  \\\n",
       "0               1          2     0     1      0    0       0     0    0    0   \n",
       "1               4         14     0     0      1    0       0     0    0    0   \n",
       "2               7         28     0     0      1    0       0     0    0    0   \n",
       "3               2          7     0     1      0    0       0     0    0    0   \n",
       "4               2          9     0     1      0    0       0     0    0    0   \n",
       "...           ...        ...   ...   ...    ...  ...     ...   ...  ...  ...   \n",
       "115067          0          3     0     1      0    0       0     0    0    0   \n",
       "115068          0          0     0     0      0    1       0     0    0    0   \n",
       "115069          0          0     0     0      0    1       0     0    0    0   \n",
       "115070          0          3     0     1      0    0       0     0    0    0   \n",
       "115071          0          0     0     0      0    0       0     0    0    0   \n",
       "\n",
       "        TCP  UDP  DHCP  ARP  ICMP  IGMP  IPv  LLC  Tot sum  Min   Max  \\\n",
       "0         1    0     0    0     0     0    1    1     1501   54   778   \n",
       "1         1    0     0    0     0     0    1    1     4151   54  1506   \n",
       "2         1    0     0    0     0     0    1    1     5942   54  1506   \n",
       "3         1    0     0    0     0     0    1    1     6391   54  1506   \n",
       "4         1    0     0    0     0     0    1    1     6553   54  1506   \n",
       "...     ...  ...   ...  ...   ...   ...  ...  ...      ...  ...   ...   \n",
       "115067    1    0     0    0     0     0    1    1       66   66    66   \n",
       "115068    0    1     0    0     0     0    1    1      152   66    86   \n",
       "115069    0    1     0    0     0     0    1    1     1460   60   436   \n",
       "115070    1    0     0    0     0     0    1    1     2192   60   436   \n",
       "115071    0    1     0    0     0     0    1    1     3861   60   446   \n",
       "\n",
       "               AVG         Std  Tot size       IAT  Number   Magnitue  \\\n",
       "0       187.625000  234.260505        54  0.000193       8  19.371371   \n",
       "1       319.307692  502.889709      1506  0.582391      13  25.182335   \n",
       "2       848.857143  692.984318      1506  0.000132       7  38.716921   \n",
       "3       532.583333  649.853376        54  0.001591      12  35.448554   \n",
       "4       436.866667  611.959352        54  0.000684      15  30.470126   \n",
       "...            ...         ...       ...       ...     ...        ...   \n",
       "115067   66.000000    0.000000        66  0.000071       1   8.124038   \n",
       "115068   76.000000   10.000000        86  0.002155       2   8.717798   \n",
       "115069  146.000000  144.706600        86  0.000656      10  15.099669   \n",
       "115070  199.272727  155.298007        66  0.000100      11  16.905620   \n",
       "115071  227.117647  162.810927       444  0.102268      17  18.665476   \n",
       "\n",
       "            Radius    Covariance   Variance  Weight  DS status  Fragments  \\\n",
       "0       321.382074 -14259.875000  11.639548      16          0          0   \n",
       "1       710.282604   -190.050000   1.019383      40          0          0   \n",
       "2       105.655099      0.000000   0.000000      12          0          0   \n",
       "3       493.924529      0.000000   0.000000      35          0          0   \n",
       "4       665.957497      0.000000   0.000000      56          0          0   \n",
       "...            ...           ...        ...     ...        ...        ...   \n",
       "115067    0.000000      0.000000   0.000000       0          0          0   \n",
       "115068   10.000000      0.000000   0.000000       0          0          0   \n",
       "115069  150.421630      0.000000   0.000000       9          0          0   \n",
       "115070  157.489555      0.000000   0.000000      10          0          0   \n",
       "115071  169.177737   -653.066667  28.782629      30          0          0   \n",
       "\n",
       "        Sequence number  flow_idle_time  flow_active_time     Label  \n",
       "0                     0    1.928810e-04          0.000193  0_normal  \n",
       "1                     0    8.030751e-01          1.298898  0_normal  \n",
       "2                     0    1.320840e-04          1.308947  0_normal  \n",
       "3                     0    1.267583e+00          1.427035  0_normal  \n",
       "4                     0    7.359980e-04          1.480285  0_normal  \n",
       "...                 ...             ...               ...       ...  \n",
       "115067                0    7.100000e-05          0.002669       TCP  \n",
       "115068                0    1.716628e+09          0.000000       UDP  \n",
       "115069                0    1.716628e+09          0.000000       UDP  \n",
       "115070                0    9.990000e-05          0.001351       TCP  \n",
       "115071                0    1.022680e-01          0.715423  0_normal  \n",
       "\n",
       "[115072 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/custom_data_sub100k.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDCqKctrHfP8",
    "outputId": "c0e845f2-415d-4659-bd97-7ef88c07ab7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115072 entries, 0 to 115071\n",
      "Data columns (total 56 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   flow_duration     115072 non-null  float64\n",
      " 1   flow_byte         115072 non-null  int64  \n",
      " 2   src_port          115072 non-null  int64  \n",
      " 3   dst_port          115072 non-null  int64  \n",
      " 4   Duration          115072 non-null  int64  \n",
      " 5   Rate              115072 non-null  float64\n",
      " 6   Srate             115072 non-null  float64\n",
      " 7   Drate             115072 non-null  int64  \n",
      " 8   fin_flag_number   115072 non-null  int64  \n",
      " 9   syn_flag_number   115072 non-null  int64  \n",
      " 10  rst_flag_number   115072 non-null  int64  \n",
      " 11  psh_flag_number   115072 non-null  int64  \n",
      " 12  ack_flag_number   115072 non-null  int64  \n",
      " 13  urg_flag_number   115072 non-null  int64  \n",
      " 14  ece_flag_number   115072 non-null  int64  \n",
      " 15  cwr_flag_number   115072 non-null  int64  \n",
      " 16  ack_count         115072 non-null  int64  \n",
      " 17  syn_count         115072 non-null  int64  \n",
      " 18  fin_count         115072 non-null  int64  \n",
      " 19  urg_count         115072 non-null  int64  \n",
      " 20  rst_count         115072 non-null  int64  \n",
      " 21  CoAP              115072 non-null  int64  \n",
      " 22  HTTP              115072 non-null  int64  \n",
      " 23  HTTPS             115072 non-null  int64  \n",
      " 24  DNS               115072 non-null  int64  \n",
      " 25  Telnet            115072 non-null  int64  \n",
      " 26  SMTP              115072 non-null  int64  \n",
      " 27  SSH               115072 non-null  int64  \n",
      " 28  IRC               115072 non-null  int64  \n",
      " 29  TCP               115072 non-null  int64  \n",
      " 30  UDP               115072 non-null  int64  \n",
      " 31  DHCP              115072 non-null  int64  \n",
      " 32  ARP               115072 non-null  int64  \n",
      " 33  ICMP              115072 non-null  int64  \n",
      " 34  IGMP              115072 non-null  int64  \n",
      " 35  IPv               115072 non-null  int64  \n",
      " 36  LLC               115072 non-null  int64  \n",
      " 37  Tot sum           115072 non-null  int64  \n",
      " 38  Min               115072 non-null  int64  \n",
      " 39  Max               115072 non-null  int64  \n",
      " 40  AVG               115072 non-null  float64\n",
      " 41  Std               115072 non-null  float64\n",
      " 42  Tot size          115072 non-null  int64  \n",
      " 43  IAT               115072 non-null  float64\n",
      " 44  Number            115072 non-null  int64  \n",
      " 45  Magnitue          115072 non-null  float64\n",
      " 46  Radius            115072 non-null  float64\n",
      " 47  Covariance        115072 non-null  float64\n",
      " 48  Variance          115072 non-null  float64\n",
      " 49  Weight            115072 non-null  int64  \n",
      " 50  DS status         115072 non-null  int64  \n",
      " 51  Fragments         115072 non-null  int64  \n",
      " 52  Sequence number   115072 non-null  int64  \n",
      " 53  flow_idle_time    115072 non-null  float64\n",
      " 54  flow_active_time  115072 non-null  float64\n",
      " 55  Label             115072 non-null  object \n",
      "dtypes: float64(12), int64(43), object(1)\n",
      "memory usage: 49.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85P62UUrIOUr",
    "outputId": "c6f8cf90-631d-48eb-94e7-ddc6a4037648"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0_normal    36163\n",
       "TCP         25814\n",
       "UDP         21135\n",
       "ICMP        17673\n",
       "ARP         14287\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "QXqAncoEY79n",
    "outputId": "339ba316-3c5e-4595-ba93-fffb8a2a580e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc = {'figure.figsize' : (10, 7)})\n",
    "ax = sns.countplot(x = 'Label', data = df)\n",
    "ax.set(xlabel = 'Type', ylabel = 'Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5a4bc1d"
   },
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bf83c94b"
   },
   "outputs": [],
   "source": [
    "def remove_outliers_lof(X_data, y_data, contamination=0.05, random_seed=None):\n",
    "    \"\"\"\n",
    "    Remove outliers from a dataset using Local Outlier Factor (LOF).\n",
    "\n",
    "    Parameters:\n",
    "    - X_data: numpy array, feature matrix\n",
    "    - y_data: numpy array, label array\n",
    "    - contamination: float, the proportion of outliers in the dataset\n",
    "    - random_seed: int or None, seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - X_no_outliers: numpy array, feature matrix without outliers\n",
    "    - y_no_outliers: numpy array, label array without outliers\n",
    "    \"\"\"\n",
    "\n",
    "    unique_classes = np.unique(y_data)\n",
    "\n",
    "    X_no_outliers = np.empty((0, X_data.shape[1]), dtype=X_data.dtype)\n",
    "    y_no_outliers = np.empty(0, dtype=y_data.dtype)\n",
    "\n",
    "    for label in unique_classes:\n",
    "        # Select samples belonging to the current class\n",
    "        # print(label)\n",
    "        class_mask = (y_data == label)\n",
    "        X_class = X_data[class_mask]\n",
    "        if label == 0:\n",
    "            X_no_outliers = np.vstack((X_no_outliers, X_class))\n",
    "            y_no_outliers = np.concatenate((y_no_outliers, y_data[class_mask]))\n",
    "        else:\n",
    "            # Apply LOF to detect outliers\n",
    "            lof = LocalOutlierFactor(contamination=contamination)\n",
    "            outliers_mask = lof.fit_predict(X_class) == -1\n",
    "\n",
    "            # Remove outliers from the current class\n",
    "            X_no_outliers = np.vstack((X_no_outliers, X_class[~outliers_mask]))\n",
    "            y_no_outliers = np.concatenate((y_no_outliers, y_data[class_mask][~outliers_mask]))\n",
    "\n",
    "    return X_no_outliers, y_no_outliers\n",
    "\n",
    "def prepare_data(data, target, cls_drop):\n",
    "    classes = np.unique(target)\n",
    "    if __MODE == \"Novelty_multi\":\n",
    "        mask = ~np.isin(classes, cls_drop)\n",
    "        known = classes[mask]\n",
    "    elif __MODE == \"1_Cls\":\n",
    "        known = \"0_normal\"\n",
    "    else:\n",
    "        known = classes\n",
    "\n",
    "\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.3, stratify = target, random_state=__SEED)\n",
    "\n",
    "\n",
    "    # Loáº¡i bá» cÃ¡c class khÃ´ng biáº¿t trong táº­p train\n",
    "    mask = np.array([y in known for y in target_train])\n",
    "\n",
    "    X_train = data_train[mask]\n",
    "    y_train = target_train[mask]\n",
    "\n",
    "    idx = y_train.argsort()\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    X_test = data_test\n",
    "    y_labels = target_test\n",
    "\n",
    "    if __MODE == \"Novelty_multi\":\n",
    "        # Test labels are 1 if novel, otherwise 0.\n",
    "        # y_test_bina = np.array([1 if cl not in known else 0 for cl in y_labels])\n",
    "        y_test = np.array([-1 if cl not in known else encoder.transform([cl])[0] for cl in y_labels])\n",
    "        # y_test = np.array([cl+\"-1\" if cl not in known else cl for cl in y_labels])\n",
    "\n",
    "\n",
    "    if __MODE == \"Supervise\":\n",
    "        # y_test_bina = np.array([1 if cl != 0 else 0 for cl in y_labels])\n",
    "\n",
    "        y_test = encoder.transform(y_labels)\n",
    "\n",
    "    if __MODE == \"1_Cls\":\n",
    "        y_test = np.array([1 if cl not in known else encoder.transform([cl])[0] for cl in y_labels])\n",
    "\n",
    "    # encoder = LabelEncoder()\n",
    "    # y_test = encoder.fit_transform(y_test)\n",
    "    # y_train = encoder.transform(y_train)\n",
    "    classes = np.unique(y_train)\n",
    "\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, classes, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "29031472"
   },
   "outputs": [],
   "source": [
    "def Get_Scaler(name):\n",
    "  # (StandardScaler, MinMaxScaler, RobustScaler, Normalizer)\n",
    "  if name == \"StandardScaler\":\n",
    "    return StandardScaler()\n",
    "  if name == \"MinMaxScaler\":\n",
    "    return MinMaxScaler()\n",
    "  if name == \"RobustScaler\":\n",
    "    return RobustScaler()\n",
    "  if name == \"Normalizer\":\n",
    "    return Normalizer()\n",
    "  if name == \"QuantileTransformer\":\n",
    "      return QuantileTransformer(output_distribution = \"normal\", random_state=__SEED)\n",
    "  return None\n",
    "\n",
    "def preprocess_data(drop_cls, data):\n",
    "    datasets = data.to_numpy()\n",
    "    labels = datasets[:,-1]\n",
    "    dataset = datasets[:,:-1]\n",
    "\n",
    "\n",
    "    ## ========================== Running Main Model ================================================\n",
    "\n",
    "    X_train, y_train, X_test, y_test, classes_tmp, encoder = prepare_data(dataset, labels, drop_cls)\n",
    "\n",
    "    # print(f\"X_train shape: {X_train.shape}\")\n",
    "    # print(f\"y_train counts: {np.unique(y_train, return_counts=True)}\")\n",
    "\n",
    "    # X_train, y_train = reduce_trainning_data(X_train, y_train)\n",
    "\n",
    "\n",
    "    ## ========================== Scaler data ================================================\n",
    "    scaler = Get_Scaler(name=__SCALER)\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Remove outliers\n",
    "    X_train, y_train= remove_outliers_lof(X_train, y_train)\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train counts: {np.unique(y_train, return_counts=True)}\")\n",
    "\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_test counts: {np.unique(y_test, return_counts=True)}\")\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, classes_tmp, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uc3k8eRaIQYU"
   },
   "source": [
    "# INNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd322d4a"
   },
   "source": [
    "### INNR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d3b4e81d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def K(X,Y=None,metric='poly',coef0=1,gamma=None,degree=3):\n",
    "    if metric == 'poly':\n",
    "        k = pairwise_kernels(X,Y=Y,metric=metric,coef0=coef0,gamma=gamma,degree=degree)\n",
    "    elif metric == 'linear':\n",
    "        k = pairwise_kernels(X,Y=Y,metric=metric)\n",
    "    elif metric == 'sigmoid':\n",
    "        k = pairwise_kernels(X,Y=Y,metric=metric,coef0=coef0,gamma=gamma)\n",
    "    elif metric == 'rbf':\n",
    "        k = pairwise_kernels(X,Y=Y,metric=metric,gamma=gamma)\n",
    "    return k\n",
    "\n",
    "def kernel_distance_matrix(matrix1 = None, matrix2 = None, kernel=None, gamma=None):\n",
    "    \"\"\"\n",
    "    Calculate the distance between two matrices using the kernel trick.\n",
    "    Parameters:\n",
    "    - matrix1: The first input matrix (NumPy array).\n",
    "    - matrix2: The second input matrix (NumPy array).\n",
    "    - gamma: The gamma parameter for the RBF kernel.\n",
    "    Returns:\n",
    "    - distance_matrix: The distance matrix between the two input matrices.\n",
    "    \"\"\"\n",
    "\n",
    "    if matrix1.shape[1] != matrix2.shape[1]:\n",
    "        raise ValueError(\"The number of features in the input matrices must be the same.\")\n",
    "    Kaa = []\n",
    "    for i in range(len(matrix1)):\n",
    "        Kaa.append(K(matrix1[i,:].reshape(1,-1),metric=kernel))\n",
    "    Kaa = np.asarray(Kaa).ravel().reshape(len(Kaa),1)\n",
    "    Kab = K(matrix1,matrix2,metric=kernel)\n",
    "    Kbb = []\n",
    "    for i in range(len(matrix2)):\n",
    "        Kbb.append(K(matrix2[i,:].reshape(1,-1),metric=kernel))\n",
    "    Kbb = np.asarray(Kbb).ravel()\n",
    "    d = Kaa-2*Kab+Kbb #shape: (matrix1,matrix2)\n",
    "    return d\n",
    "\n",
    "def calculate_accuracy_for_label(y_true, y_predict, label):\n",
    "    \"\"\"\n",
    "    Calculate accuracy for a specific label.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: The true labels (1D NumPy array).\n",
    "    - y_predict: The predicted labels (1D NumPy array).\n",
    "    - label: The specific label for which to calculate accuracy.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: The accuracy for the specified label.\n",
    "    \"\"\"\n",
    "    # Create a boolean mask for the specified label\n",
    "    mask = (y_true == label)\n",
    "\n",
    "    # Extract true labels and predicted labels for the specified label\n",
    "    true_labels_for_label = y_true[mask]\n",
    "    predicted_labels_for_label = y_predict[mask]\n",
    "\n",
    "\n",
    "    # Calculate accuracy for the specified label\n",
    "    accuracy = np.mean(true_labels_for_label == predicted_labels_for_label)\n",
    "    # print(accuracy)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "class kINN:\n",
    "    def __init__(self, R=1, kernel=\"linear\", mode = \"Supervise\"):\n",
    "        self.R = R\n",
    "        self.kernel = kernel\n",
    "        self.distance_matrix = None\n",
    "        self.cluster_labels = None\n",
    "        self.cluster_map = None\n",
    "        self.N = None\n",
    "        # self.n_clusters = n_clusters\n",
    "        self.X = None\n",
    "        self.M = None\n",
    "        self.is_fit = False\n",
    "        self.DNN_test = None\n",
    "        self.distance_matrix_test = None\n",
    "        self.mode = mode\n",
    "\n",
    "\n",
    "\n",
    "    def _Bruteforce_threshold(self, y_test, y_pred, scores):\n",
    "        # d = Decimal(np.min(scores))\n",
    "        # min_th = max(1e-8,pow(10, d.as_tuple().exponent))\n",
    "        # d = Decimal(np.max(scores))\n",
    "        # max_th = min(1e-2,pow(10, d.as_tuple().exponent))\n",
    "\n",
    "        # print(\"======================= DEBUG =======================\")\n",
    "        # print(min_th, max_th)\n",
    "        # print(\"======================= DEBUG =======================\")\n",
    "        min_th = 1e-7\n",
    "        max_th = 1e-1\n",
    "        # __step = int(max_th / min_th)\n",
    "        __step = 10000\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        mcc = 0\n",
    "        ndr = 0\n",
    "        y_pred_adv = y_pred\n",
    "\n",
    "\n",
    "        __rag = np.unique(y_test)\n",
    "        thr = -np.ones(len(__rag))\n",
    "\n",
    "        for id in __rag[1:]:\n",
    "            # print(\"DEBUG:\", id)\n",
    "            for x in np.linspace(min_th, max_th, num=__step):\n",
    "                y_pred_adv_tmp = np.array([-1 if (y_p == id) and (sc > x) else y_p for y_p, sc in zip( y_pred,scores)])\n",
    "                mcc_tmp = matthews_corrcoef(y_test, y_pred_adv_tmp)\n",
    "                ndr_tmp = calculate_accuracy_for_label(y_test, y_pred_adv_tmp, -1)\n",
    "                if np.mean([mcc_tmp*2,ndr_tmp]) > np.mean([mcc*2,ndr]):\n",
    "                    y_pred_adv = y_pred_adv_tmp\n",
    "                    mcc = mcc_tmp\n",
    "                    ndr = ndr_tmp\n",
    "                    thr[id] = x\n",
    "            y_pred = y_pred_adv\n",
    "        print(\"DEBUG - update mcc:\", mcc, ndr, thr)\n",
    "        return y_pred_adv, mcc, thr\n",
    "\n",
    "\n",
    "    def _Bruteforce_threshold_1_cls(self, y_test, y_pred, scores):\n",
    "          # d = Decimal(np.min(scores))\n",
    "          # min_th = max(1e-8,pow(10, d.as_tuple().exponent))\n",
    "          # d = Decimal(np.max(scores))\n",
    "          # max_th = min(1e-2,pow(10, d.as_tuple().exponent))\n",
    "\n",
    "          # print(\"======================= DEBUG =======================\")\n",
    "          # print(min_th, max_th)\n",
    "          # print(\"======================= DEBUG =======================\")\n",
    "          min_th = 1e-7\n",
    "          max_th = 1e-1\n",
    "          # __step = int(max_th / min_th)\n",
    "          __step = 10000\n",
    "          mcc = matthews_corrcoef(y_test, y_pred)\n",
    "          mcc = 0\n",
    "          ndr = 0\n",
    "          y_pred_adv = y_pred\n",
    "\n",
    "\n",
    "          __rag = np.unique(y_test)\n",
    "          thr = -np.ones(len(__rag))\n",
    "\n",
    "\n",
    "          # for id in __rag[0]:\n",
    "          id = 0\n",
    "          for x in np.linspace(min_th, max_th, num=__step):\n",
    "              y_pred_adv_tmp = np.array([1 if (y_p == id) and (sc > x) else y_p for y_p, sc in zip( y_pred,scores)])\n",
    "              mcc_tmp = matthews_corrcoef(y_test, y_pred_adv_tmp)\n",
    "              ndr_tmp = calculate_accuracy_for_label(y_test, y_pred_adv_tmp, 1)\n",
    "              if np.mean([mcc_tmp*2,ndr_tmp]) > np.mean([mcc*2,ndr]):\n",
    "                  y_pred_adv = y_pred_adv_tmp\n",
    "                  mcc = mcc_tmp\n",
    "                  ndr = ndr_tmp\n",
    "                  thr[id] = x\n",
    "          y_pred = y_pred_adv\n",
    "\n",
    "\n",
    "          print(\"DEBUG - update mcc:\", mcc, ndr, thr)\n",
    "          return y_pred_adv, mcc, thr\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, X, y = None, single = False, type = \"distance\"):\n",
    "        \"\"\"\n",
    "        Fit the kINN model to the input data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data, a 2D numpy array where each row represents a sample.\n",
    "        - y: Input label, a array where each row represents a label for corresponding label\n",
    "        - type: the strategy to calculate distance, support:\n",
    "                                                            + \"distance\" - use only distance\n",
    "                                                            + \"density\" - use LOF score as weight when calculate distance\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        if (y is None) and (self.mode == \"1_Cls\"):\n",
    "          # -np.ones(self.N, dtype=int)\n",
    "          y = np.zeros(X.shape[0], dtype=int)\n",
    "        self._fit_classify(X,y,type)\n",
    "        self.is_fit = True\n",
    "        if single == True:\n",
    "            X_new = self.__map_to_single_point(X)\n",
    "\n",
    "            return X_new, self.cluster_labels, self.cluster_map\n",
    "        else:\n",
    "            return self.cluster_labels, self.cluster_map\n",
    "\n",
    "\n",
    "    def _calculate_lof(self, dis_mat, k_dis, d_nn, N_cnt):\n",
    "        # calculate reachability distance\n",
    "\n",
    "        re_dis_k = np.array([ [ max(dis_mat[i,k],k_dis[k]) for k in range(N_cnt) ] for i in range(N_cnt)])\n",
    "\n",
    "        # calculate Local Reachability Density (LRD)\n",
    "\n",
    "        lrd = np.array([1. / np.mean(re_dis_k[x, d_nn[x]]) for x in range(N_cnt)])\n",
    "\n",
    "        # calculate LOF\n",
    "        lof = np.array([np.mean(lrd[d_nn[x]]) / lrd[x] for x in range(N_cnt)])\n",
    "\n",
    "        return lof\n",
    "\n",
    "    def _fit_classify(self, X, y, type=\"distance\"):\n",
    "        N = X.shape[0]\n",
    "    \n",
    "        D_NN = np.empty((N,), dtype=object)\n",
    "        INNR = np.empty((N,), dtype=object)\n",
    "    \n",
    "        classes, cls_cnt = np.unique(y, return_counts=True)\n",
    "    \n",
    "        for cls, N_cnt in zip(classes, cls_cnt):\n",
    "            indicates = np.asarray(y == cls).nonzero()[0]\n",
    "            X_cls = X[indicates]\n",
    "            y_cls = y[indicates]\n",
    "    \n",
    "            dis_mat = kernel_distance_matrix(matrix1=X_cls, matrix2=X_cls, kernel=self.kernel)\n",
    "    \n",
    "            if type == \"density\":\n",
    "                k_dis = -np.ones(N_cnt, dtype=float)\n",
    "                d_nn = np.empty((N_cnt,), dtype=object)\n",
    "                re_dis_k = -np.ones((N_cnt, N_cnt), dtype=float)\n",
    "    \n",
    "                for i in range(N_cnt):\n",
    "                    dis_mat[i, i] = 0\n",
    "                    tmp = dis_mat[i, :].argsort()\n",
    "    \n",
    "                    # Some case that 2 point are too close\n",
    "                    dnn_tmp = [i]\n",
    "                    cnt = 0\n",
    "                    for x in tmp:\n",
    "                        if abs(dis_mat[i, dnn_tmp[-1]] - dis_mat[i, x]) > 1e-9:\n",
    "                            dnn_tmp.append(x)\n",
    "                            cnt += 1\n",
    "                            k_dis[i] = dis_mat[i, x]\n",
    "                        else:\n",
    "                            dnn_tmp.append(x)\n",
    "    \n",
    "                        if cnt >= self.R:\n",
    "                            break\n",
    "                    d_nn[i] = np.array(dnn_tmp[1:])\n",
    "    \n",
    "                lof = self._calculate_lof(dis_mat, k_dis, d_nn, N_cnt)\n",
    "    \n",
    "                # Update new matrix\n",
    "                dis_mat = np.array([[dis_mat[i, k] * lof[k] for k in range(N_cnt)] for i in range(N_cnt)])\n",
    "    \n",
    "            # calculate D_N\n",
    "            for i in range(N_cnt):\n",
    "                dis_mat[i, i] = 0\n",
    "                tmp = dis_mat[i, :].argsort()\n",
    "    \n",
    "                id = indicates[i]\n",
    "                D_NN[id] = np.array(indicates[tmp])\n",
    "    \n",
    "                # Some case that 2 point are too close\n",
    "                dnn_tmp = [i]\n",
    "                cnt = 0\n",
    "                for x in tmp:\n",
    "                    if abs(dis_mat[i, dnn_tmp[-1]] - dis_mat[i, x]) > 1e-9:\n",
    "                        dnn_tmp.append(x)\n",
    "                        cnt += 1\n",
    "                    else:\n",
    "                        dnn_tmp.append(x)\n",
    "    \n",
    "                    if cnt >= self.R:\n",
    "                        break\n",
    "    \n",
    "                D_NN[id] = np.array(indicates[dnn_tmp[1:]])\n",
    "    \n",
    "            self.D_NN = D_NN\n",
    "    \n",
    "            for i in tqdm(indicates, desc=f\"Processing class {cls}\"):\n",
    "                NN = D_NN[i]\n",
    "                tmp = []\n",
    "                for p in NN:\n",
    "                    p_near_neighbor = D_NN[p]\n",
    "                    if i in p_near_neighbor:\n",
    "                        tmp.append(p)\n",
    "    \n",
    "                pair = (i, tmp)\n",
    "                INNR[i] = pair\n",
    "    \n",
    "        self.INNR = INNR\n",
    "        self.N = N\n",
    "        self.cluster_labels, self.no_cluser = self._label_clusters()\n",
    "    \n",
    "        cluster_map = np.full(self.no_cluser, -1)\n",
    "    \n",
    "        for x_tmp, y_tmp in zip(self.cluster_labels, y):\n",
    "            if cluster_map[x_tmp] == -1:\n",
    "                cluster_map[x_tmp] = y_tmp\n",
    "            else:\n",
    "                if cluster_map[x_tmp] != y_tmp:\n",
    "                    print(\"Debug - Loi KNN\")\n",
    "    \n",
    "        self.cluster_map = cluster_map\n",
    "\n",
    "\n",
    "    # def _fit_cluster(self,X):\n",
    "    #     N = X.shape[0]\n",
    "    #     dis_mat = kernel_distance_matrix(matrix1 = X, matrix2 = X, kernel = self.kernel)\n",
    "    #     D_NN = []\n",
    "    #     for i in range(N):\n",
    "    #         dis_mat[i,i] = 0\n",
    "    #         tmp = dis_mat[i,].argsort()\n",
    "    #         D_NN.append(tmp)\n",
    "\n",
    "    #     D_NN = np.array(D_NN)\n",
    "    #     self.D_NN = D_NN\n",
    "    #     INNR = []\n",
    "\n",
    "    #     for i in range(N):\n",
    "    #         NN = D_NN[i, 1:self.R+1]\n",
    "\n",
    "        #     tmp = []\n",
    "        #     for p in NN:\n",
    "        #         p_near_neighbor = D_NN[p, 1:self.R+1]\n",
    "        #         if i in p_near_neighbor:\n",
    "        #             tmp.append(p)\n",
    "\n",
    "        #     pair = (i, tmp)\n",
    "        #     INNR.append(pair)\n",
    "        # self.INNR = INNR\n",
    "\n",
    "        # self.N = N\n",
    "        # self.cluster_labels, self.no_cluser = self._label_clusters()\n",
    "\n",
    "    def _label_clusters(self):\n",
    "        \"\"\"\n",
    "        Label clusters using deep find search (DFS) algorithm.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data, a 2D numpy array where each row represents a sample.\n",
    "\n",
    "        Returns:\n",
    "        - labels: A numpy array containing cluster labels for each sample.\n",
    "\n",
    "        \"\"\"\n",
    "        # print(self.INN)\n",
    "        labels = -np.ones(self.N, dtype=int)\n",
    "        current_label = 0\n",
    "\n",
    "        # INNR = sorted(self.INNR,key=lambda x: len(x[1]), reverse=True)\n",
    "        for x in self.INNR:\n",
    "            id = x[0]\n",
    "            if labels[id] == -1:\n",
    "                queue = [id]\n",
    "                labels[id] = current_label\n",
    "                # _debug = 0\n",
    "                for q in queue:\n",
    "                    neighbors = self.INNR[q][1]\n",
    "                    for neighbor in neighbors:\n",
    "                        if labels[neighbor] == -1:\n",
    "                            queue.append(neighbor)\n",
    "                            labels[neighbor] = current_label\n",
    "                current_label += 1\n",
    "        return labels, current_label\n",
    "\n",
    "    def _dfs_label_clusters(self, i, current_label, labels):\n",
    "        \"\"\"\n",
    "        DFS algorithm to label clusters.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data, a 2D numpy array where each row represents a sample.\n",
    "        - i: Index of the current sample being explored.\n",
    "        - current_label: Current cluster label.\n",
    "        - labels: A numpy array containing cluster labels for each sample.\n",
    "\n",
    "        \"\"\"\n",
    "        if labels[i] != -1:\n",
    "            return\n",
    "\n",
    "        labels[i] = current_label\n",
    "\n",
    "        neighbors = self.INNR[i][1]\n",
    "        for neighbor in neighbors:\n",
    "            #\n",
    "            self._dfs_label_clusters(neighbor, current_label, labels)\n",
    "\n",
    "    def __map_to_single_point(self, X):\n",
    "\n",
    "        a = self.cluster_labels\n",
    "        x_new = []\n",
    "        a_new = []\n",
    "        for cl in np.unique(a):\n",
    "            mask = np.isin(a, cl)\n",
    "            known = X[mask]\n",
    "            a_new.append(self.cluster_map[cl])\n",
    "        # print(x_new)\n",
    "        # print(a_new)\n",
    "        self.cluster_labels = np.array(a_new)\n",
    "\n",
    "\n",
    "        return np.array(x_new)\n",
    "\n",
    "    def find_nearest_neighbors(self, X, x_i):\n",
    "        \"\"\"\n",
    "        Find the R nearest neighbors of x_i using kernel trick.\n",
    "\n",
    "        Parameters:\n",
    "        - x_i: The input sample.\n",
    "\n",
    "        Returns:\n",
    "        - neighbors: A set of R nearest neighbors for x_i.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.distance_matrix is None:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "\n",
    "        # Calculate kernel vector\n",
    "        kernel_vector = self.distance_matrix[x_i].flatten()\n",
    "\n",
    "        # Get indices of R nearest neighbors\n",
    "        nearest_indices = np.argsort(kernel_vector)[1:self.R+1]\n",
    "\n",
    "        return set(nearest_indices)\n",
    "\n",
    "\n",
    "    def predict(self, X_test, y = None):\n",
    "        \"\"\"\n",
    "        Predict the cluster labels for the input samples.\n",
    "\n",
    "        Parameters:\n",
    "        - X_test: Input data, a 2D numpy array where each row represents a sample.\n",
    "\n",
    "        Returns:\n",
    "        - predicted_labels: A numpy array containing predicted cluster labels for each sample.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.is_fit == False:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "\n",
    "\n",
    "        N_test = X_test.shape[0]\n",
    "        self.M = N_test\n",
    "        dis_mat_X_test = kernel_distance_matrix(matrix1 = X_test, matrix2 = self.X, kernel = self.kernel)\n",
    "        self.distance_matrix_test = dis_mat_X_test\n",
    "        D_NN_test = []\n",
    "        # print(\"Khoáº£ng cÃ¡ch X_test -> X_train:\\n \",dis_mat_X_test,\"\\n\")\n",
    "        for i in range(N_test):\n",
    "            # dis_mat_X_test[i,i] = 0\n",
    "            tmp = dis_mat_X_test[i,].argsort()\n",
    "            D_NN_test.append(tmp)\n",
    "\n",
    "        D_NN_test = np.array(D_NN_test)\n",
    "        # print(D_NN_test.shape)\n",
    "        self.D_NN_test = D_NN_test\n",
    "        INNR_X_test = []\n",
    "        # TÃ¬m INNR_X_test\n",
    "        for i in range(N_test):\n",
    "            NN = D_NN_test[i, 1:self.R+1]\n",
    "            # print(NN)\n",
    "            tmp = []\n",
    "            for p in NN:\n",
    "                p_near_neighbor = D_NN_test.T[p, 1:self.R+1]\n",
    "                # print(\"neighbor: \",p_near_neighbor)\n",
    "                if i in p_near_neighbor:\n",
    "                    # print(p_near_neighbor)\n",
    "                    tmp.append(p)\n",
    "            pair = (i, tmp)\n",
    "            # print(pair)\n",
    "            INNR_X_test.append(pair)\n",
    "        self.INNR_test = INNR_X_test\n",
    "\n",
    "\n",
    "        if self.mode == \"Supervise\":\n",
    "            labels = self._predict_multi()\n",
    "            return labels\n",
    "        elif self.mode == \"Novelty_multi\":\n",
    "            labels,mcc, threshold  = self._predict_novelty(y)\n",
    "            return labels , mcc, threshold\n",
    "        else:\n",
    "            labels,mcc, threshold = self._predict_1Class(y)\n",
    "            return labels, mcc, threshold\n",
    "\n",
    "\n",
    "\n",
    "    def _predict_multi(self):\n",
    "        labels = -np.ones(self.M, dtype=int)\n",
    "        # c = 0\n",
    "        for pair in self.INNR_test:\n",
    "                idx = pair[0]\n",
    "                if pair[1] != []:  # Kiá»ƒm tra xem danh sÃ¡ch neighbor cÃ³ rá»—ng khÃ´ng\n",
    "                    neighbors = pair[1]\n",
    "                    # print(id, \"neigibor = \",neighbors)\n",
    "                    labels[idx] = self.cluster_map[self.cluster_labels[neighbors[0]]]\n",
    "                    # c+= 1\n",
    "                    # print(self.cluster_labels[neighbors[0]])\n",
    "                else:\n",
    "                    labels[idx] = self.cluster_map[self.cluster_labels[self.D_NN_test[idx][0]]]\n",
    "        # print(\"Count: \",c)\n",
    "        return labels\n",
    "\n",
    "\n",
    "    def _predict_novelty(self, y):\n",
    "        scores_mat = self.distance_matrix_test\n",
    "        y_pred = [self.cluster_labels[x] for x in np.argmin(scores_mat, axis=1)]\n",
    "\n",
    "        for i in range(self.M):\n",
    "            y_pred[i] = self.cluster_map[y_pred[i]]\n",
    "\n",
    "        scores = np.amin(scores_mat, axis=1)\n",
    "        y_pred_adv, mcc, threshold = self._Bruteforce_threshold(y, y_pred, scores)\n",
    "\n",
    "\n",
    "        print(f\"MCC: {mcc}\", f\"threshold: {threshold}\")\n",
    "\n",
    "        return y_pred_adv, mcc, threshold\n",
    "\n",
    "\n",
    "    def _predict_1Class(self,y):\n",
    "\n",
    "        scores_mat = self.distance_matrix_test\n",
    "        # print(scores_mat)\n",
    "        # y_pred = [self.cluster_labels[x] for x in np.argmin(scores_mat, axis=1)]\n",
    "\n",
    "        # for i in range(self.M):\n",
    "        #     y_pred[i] = self.cluster_map[y_pred[i]]\n",
    "        y_pred = np.zeros(self.M, dtype = int)\n",
    "        scores = np.amin(scores_mat, axis=1)\n",
    "        y_pred_adv, mcc, threshold = self._Bruteforce_threshold_1_cls(y, y_pred, scores)\n",
    "        # print(\"DEBUG- y_pred: \", y_pred)\n",
    "\n",
    "        print(f\"MCC: {mcc}\", f\"threshold: {threshold}\")\n",
    "\n",
    "        return y_pred_adv, mcc, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (77787, 55)\n",
      "y_train counts: (array([0, 1, 2, 3, 4]), array([25314,  9501, 11752, 17166, 14054]))\n",
      "X_test shape: (34522, 55)\n",
      "y_test counts: (array([0, 1, 2, 3, 4]), array([10849,  4286,  5302,  7744,  6341]))\n",
      "Begin Fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing class 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25314/25314 [00:01<00:00, 15098.62it/s]\n",
      "Processing class 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9501/9501 [00:00<00:00, 28883.51it/s]\n",
      "Processing class 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11752/11752 [00:00<00:00, 16327.20it/s]\n",
      "Processing class 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17166/17166 [00:00<00:00, 17967.22it/s]\n",
      "Processing class 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14054/14054 [00:00<00:00, 19323.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Fit\n",
      "Begin Predict\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone Fit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBegin Predict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mkinn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 436\u001b[0m, in \u001b[0;36mkINN.predict\u001b[0;34m(self, X_test, y)\u001b[0m\n\u001b[1;32m    434\u001b[0m N_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;241m=\u001b[39m N_test\n\u001b[0;32m--> 436\u001b[0m dis_mat_X_test \u001b[38;5;241m=\u001b[39m \u001b[43mkernel_distance_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance_matrix_test \u001b[38;5;241m=\u001b[39m dis_mat_X_test\n\u001b[1;32m    438\u001b[0m D_NN_test \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Parameters ----------------------------------------------------------------\n",
    "__SEED = 42\n",
    "__KNN = 25\n",
    "__KERNEL = \"rbf\"\n",
    "__TYPE = \"density\"\n",
    "__TARGET = \"Label\"\n",
    "__SCALER = \"QuantileTransformer\"\n",
    "drop_cls = [\"*\"]\n",
    "__MODE = \"Supervise\"\n",
    "# Test\n",
    "X_train, y_train, X_test, y_test, classes_tmp, encoder = preprocess_data(drop_cls, df.copy())\n",
    "print(\"Begin Fit\")\n",
    "kinn_model = kINN(R = __KNN, kernel=__KERNEL, mode = __MODE)\n",
    "cluster_train, cluster_map = kinn_model.fit(X_train, y_train, False ,type= __TYPE)\n",
    "print(\"Done Fit\")\n",
    "print(\"Begin Predict\")\n",
    "# y_pred = kinn_model.predict(X_test)\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model -> Load model -> Predict\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LÆ°u cÃ¡c Ä‘á»‘i tÆ°á»£ng vÃ o file\n",
    "with open(\"kinn_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"model\": kinn_model,\n",
    "        \"cluster_train\": cluster_train,\n",
    "        \"cluster_map\": cluster_map,\n",
    "        \"parameters\": {\n",
    "            \"SEED\": __SEED,\n",
    "            \"KNN\": __KNN,\n",
    "            \"KERNEL\": __KERNEL,\n",
    "            \"TYPE\": __TYPE,\n",
    "            \"TARGET\": __TARGET,\n",
    "            \"SCALER\": __SCALER,\n",
    "            \"MODE\": __MODE\n",
    "        }\n",
    "    }, f)\n",
    "\n",
    "print(\"Model vÃ  cÃ¡c thÃ nh pháº§n Ä‘Ã£ Ä‘Æ°á»£c lÆ°u thÃ nh cÃ´ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cls = [\"*\"]\n",
    "__MODE = \"Supervise\"\n",
    "__SEED = 42\n",
    "__SCALER = \"QuantileTransformer\"\n",
    "# X_train, y_train, X_test, y_test, classes_tmp, encoder = preprocess_data(drop_cls, df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!\n",
      "ThÃ´ng sá»‘ Ä‘Ã£ lÆ°u: {'SEED': 42, 'KNN': 25, 'KERNEL': 'rbf', 'TYPE': 'density', 'TARGET': 'Label', 'SCALER': 'QuantileTransformer', 'MODE': 'Supervise'}\n"
     ]
    }
   ],
   "source": [
    "# Load model vÃ  cÃ¡c thÃ nh pháº§n tá»« file\n",
    "with open(\"kinn_model.pkl\", \"rb\") as f:\n",
    "    saved_data = pickle.load(f)\n",
    "\n",
    "# Truy xuáº¥t cÃ¡c thÃ nh pháº§n\n",
    "kinn_model_loaded = saved_data[\"model\"]\n",
    "cluster_train = saved_data[\"cluster_train\"]\n",
    "cluster_map = saved_data[\"cluster_map\"]\n",
    "parameters = saved_data[\"parameters\"]\n",
    "\n",
    "# In thÃ´ng tin Ä‘Ã£ táº£i\n",
    "print(\"Model Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!\")\n",
    "print(\"ThÃ´ng sá»‘ Ä‘Ã£ lÆ°u:\", parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Get_Scaler(name=__SCALER)\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import sniff\n",
    "from Feature_extraction import Feature_extraction\n",
    "\n",
    "# Táº¡o má»™t instance cá»§a lá»›p Feature_extraction\n",
    "feature_extractor = Feature_extraction()\n",
    "\n",
    "# HÃ m callback Ä‘á»ƒ xá»­ lÃ½ má»—i gÃ³i tin Ä‘Æ°á»£c capture\n",
    "def process_packet(packet):\n",
    "    raw_packet = bytes(packet)\n",
    "    features = feature_extractor.pcap_evaluation(raw_packet)\n",
    "    # print(features)\n",
    "    # for feature in features:\n",
    "    #     print(f\"{feature}: {type(feature)}\")\n",
    "    features_tranform = scaler.transform(features)\n",
    "    # print(features_tranform)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture cÃ¡c gÃ³i tin máº¡ng realtime trÃªn card NIC cá»¥ thá»ƒ\n",
    "sniff(prn=process_packet, count=1, iface=\"Wi-Fi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kinn_model_loaded.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96     10928\n",
      "           1       0.95      0.95      0.95      4298\n",
      "           2       1.00      1.00      1.00      5296\n",
      "           3       0.98      0.99      0.99      7705\n",
      "           4       0.98      0.99      0.98      6295\n",
      "\n",
      "    accuracy                           0.97     34522\n",
      "   macro avg       0.97      0.97      0.97     34522\n",
      "weighted avg       0.97      0.97      0.97     34522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 4558002,
     "sourceId": 7787318,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4689630,
     "sourceId": 8536977,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
