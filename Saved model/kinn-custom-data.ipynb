{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGUgpF_54cvP",
    "outputId": "0a10fc0d-8c96-4b91-849c-1fb7caa3fbe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in ./.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.local/lib/python3.10/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.local/lib/python3.10/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./.local/lib/python3.10/site-packages (from seaborn) (3.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/tljh/user/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/tljh/user/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/tljh/user/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 13:08:19.977534: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-28 13:08:19.987352: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-28 13:08:19.999806: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-28 13:08:19.999827: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-28 13:08:20.010633: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-28 13:08:20.498155: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyod in ./.local/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: joblib in ./.local/lib/python3.10/site-packages (from pyod) (1.4.2)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from pyod) (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.19 in ./.local/lib/python3.10/site-packages (from pyod) (1.26.4)\n",
      "Requirement already satisfied: numba>=0.51 in ./.local/lib/python3.10/site-packages (from pyod) (0.60.0)\n",
      "Requirement already satisfied: scipy>=1.5.1 in ./.local/lib/python3.10/site-packages (from pyod) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in ./.local/lib/python3.10/site-packages (from pyod) (1.5.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./.local/lib/python3.10/site-packages (from numba>=0.51->pyod) (0.43.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.local/lib/python3.10/site-packages (from scikit-learn>=0.22.0->pyod) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->pyod) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib->pyod) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->pyod) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->pyod) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from matplotlib->pyod) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./.local/lib/python3.10/site-packages (from matplotlib->pyod) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/tljh/user/lib/python3.10/site-packages (from matplotlib->pyod) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.local/lib/python3.10/site-packages (from matplotlib->pyod) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/tljh/user/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->pyod) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, MinMaxScaler, Normalizer, RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import keras\n",
    "\n",
    "#from keras.utils.np_utils import to_categorical\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import urllib.request\n",
    "import shutil\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "from typing import List, Tuple, Generator, Iterator\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "!pip install pyod\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.inne import INNE\n",
    "# import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL4r6ensYSYp"
   },
   "source": [
    "###### **Preprocessing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "TeARnBrHX12x",
    "outputId": "f912cdaa-bbd8-4750-f1f5-b69bc17098ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>flow_byte</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Srate</th>\n",
       "      <th>Drate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>psh_flag_number</th>\n",
       "      <th>ack_flag_number</th>\n",
       "      <th>urg_flag_number</th>\n",
       "      <th>ece_flag_number</th>\n",
       "      <th>cwr_flag_number</th>\n",
       "      <th>ack_count</th>\n",
       "      <th>syn_count</th>\n",
       "      <th>fin_count</th>\n",
       "      <th>urg_count</th>\n",
       "      <th>rst_count</th>\n",
       "      <th>CoAP</th>\n",
       "      <th>HTTP</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DNS</th>\n",
       "      <th>Telnet</th>\n",
       "      <th>SMTP</th>\n",
       "      <th>SSH</th>\n",
       "      <th>IRC</th>\n",
       "      <th>TCP</th>\n",
       "      <th>UDP</th>\n",
       "      <th>DHCP</th>\n",
       "      <th>ARP</th>\n",
       "      <th>ICMP</th>\n",
       "      <th>IGMP</th>\n",
       "      <th>IPv</th>\n",
       "      <th>LLC</th>\n",
       "      <th>Tot sum</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>AVG</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Magnitue</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Covariance</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Weight</th>\n",
       "      <th>DS status</th>\n",
       "      <th>Fragments</th>\n",
       "      <th>Sequence number</th>\n",
       "      <th>flow_idle_time</th>\n",
       "      <th>flow_active_time</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000193</td>\n",
       "      <td>832</td>\n",
       "      <td>80</td>\n",
       "      <td>61786</td>\n",
       "      <td>64</td>\n",
       "      <td>10369.107540</td>\n",
       "      <td>10369.107540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1501</td>\n",
       "      <td>54</td>\n",
       "      <td>778</td>\n",
       "      <td>187.625000</td>\n",
       "      <td>234.260505</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>8</td>\n",
       "      <td>19.371371</td>\n",
       "      <td>321.382074</td>\n",
       "      <td>-14259.875000</td>\n",
       "      <td>11.639548</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.928810e-04</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.298898</td>\n",
       "      <td>7558</td>\n",
       "      <td>443</td>\n",
       "      <td>35442</td>\n",
       "      <td>55</td>\n",
       "      <td>11.548251</td>\n",
       "      <td>11.548251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4151</td>\n",
       "      <td>54</td>\n",
       "      <td>1506</td>\n",
       "      <td>319.307692</td>\n",
       "      <td>502.889709</td>\n",
       "      <td>1506</td>\n",
       "      <td>0.582391</td>\n",
       "      <td>13</td>\n",
       "      <td>25.182335</td>\n",
       "      <td>710.282604</td>\n",
       "      <td>-190.050000</td>\n",
       "      <td>1.019383</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.030751e-01</td>\n",
       "      <td>1.298898</td>\n",
       "      <td>0_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.308947</td>\n",
       "      <td>21437</td>\n",
       "      <td>443</td>\n",
       "      <td>35442</td>\n",
       "      <td>55</td>\n",
       "      <td>22.155212</td>\n",
       "      <td>22.155212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5942</td>\n",
       "      <td>54</td>\n",
       "      <td>1506</td>\n",
       "      <td>848.857143</td>\n",
       "      <td>692.984318</td>\n",
       "      <td>1506</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>7</td>\n",
       "      <td>38.716921</td>\n",
       "      <td>105.655099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.320840e-04</td>\n",
       "      <td>1.308947</td>\n",
       "      <td>0_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.427035</td>\n",
       "      <td>1477</td>\n",
       "      <td>35441</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>5.606030</td>\n",
       "      <td>5.606030</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6391</td>\n",
       "      <td>54</td>\n",
       "      <td>1506</td>\n",
       "      <td>532.583333</td>\n",
       "      <td>649.853376</td>\n",
       "      <td>54</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>12</td>\n",
       "      <td>35.448554</td>\n",
       "      <td>493.924529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.267583e+00</td>\n",
       "      <td>1.427035</td>\n",
       "      <td>0_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.480285</td>\n",
       "      <td>1585</td>\n",
       "      <td>35441</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>6.755456</td>\n",
       "      <td>6.755456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6553</td>\n",
       "      <td>54</td>\n",
       "      <td>1506</td>\n",
       "      <td>436.866667</td>\n",
       "      <td>611.959352</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>15</td>\n",
       "      <td>30.470126</td>\n",
       "      <td>665.957497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.359980e-04</td>\n",
       "      <td>1.480285</td>\n",
       "      <td>0_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115067</th>\n",
       "      <td>0.002669</td>\n",
       "      <td>280</td>\n",
       "      <td>44216</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>1498.634748</td>\n",
       "      <td>1498.634748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1</td>\n",
       "      <td>8.124038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.100000e-05</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115068</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>86</td>\n",
       "      <td>53608</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "      <td>1498.634748</td>\n",
       "      <td>1498.634748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>66</td>\n",
       "      <td>86</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>86</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>2</td>\n",
       "      <td>8.717798</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.716628e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115069</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>86</td>\n",
       "      <td>40828</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "      <td>43.190489</td>\n",
       "      <td>43.190489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1460</td>\n",
       "      <td>60</td>\n",
       "      <td>436</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>144.706600</td>\n",
       "      <td>86</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>10</td>\n",
       "      <td>15.099669</td>\n",
       "      <td>150.421630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.716628e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>UDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115070</th>\n",
       "      <td>0.001351</td>\n",
       "      <td>280</td>\n",
       "      <td>44246</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>2961.033533</td>\n",
       "      <td>2961.033533</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2192</td>\n",
       "      <td>60</td>\n",
       "      <td>436</td>\n",
       "      <td>199.272727</td>\n",
       "      <td>155.298007</td>\n",
       "      <td>66</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>11</td>\n",
       "      <td>16.905620</td>\n",
       "      <td>157.489555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.990000e-05</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115071</th>\n",
       "      <td>0.715423</td>\n",
       "      <td>5058</td>\n",
       "      <td>49126</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>16.773291</td>\n",
       "      <td>16.773291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3861</td>\n",
       "      <td>60</td>\n",
       "      <td>446</td>\n",
       "      <td>227.117647</td>\n",
       "      <td>162.810927</td>\n",
       "      <td>444</td>\n",
       "      <td>0.102268</td>\n",
       "      <td>17</td>\n",
       "      <td>18.665476</td>\n",
       "      <td>169.177737</td>\n",
       "      <td>-653.066667</td>\n",
       "      <td>28.782629</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.022680e-01</td>\n",
       "      <td>0.715423</td>\n",
       "      <td>0_normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115072 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        flow_duration  flow_byte  src_port  dst_port  Duration          Rate  \\\n",
       "0            0.000193        832        80     61786        64  10369.107540   \n",
       "1            1.298898       7558       443     35442        55     11.548251   \n",
       "2            1.308947      21437       443     35442        55     22.155212   \n",
       "3            1.427035       1477     35441        80       128      5.606030   \n",
       "4            1.480285       1585     35441        80       128      6.755456   \n",
       "...               ...        ...       ...       ...       ...           ...   \n",
       "115067       0.002669        280     44216        80        64   1498.634748   \n",
       "115068       0.000000         86     53608        53        64   1498.634748   \n",
       "115069       0.000000         86     40828        53        64     43.190489   \n",
       "115070       0.001351        280     44246        80        64   2961.033533   \n",
       "115071       0.715423       5058     49126      1900         2     16.773291   \n",
       "\n",
       "               Srate  Drate  fin_flag_number  syn_flag_number  \\\n",
       "0       10369.107540      0                0                0   \n",
       "1          11.548251      0                0                0   \n",
       "2          22.155212      0                0                0   \n",
       "3           5.606030      0                1                0   \n",
       "4           6.755456      0                0                0   \n",
       "...              ...    ...              ...              ...   \n",
       "115067   1498.634748      0                0                0   \n",
       "115068   1498.634748      0                0                0   \n",
       "115069     43.190489      0                0                0   \n",
       "115070   2961.033533      0                0                0   \n",
       "115071     16.773291      0                0                0   \n",
       "\n",
       "        rst_flag_number  psh_flag_number  ack_flag_number  urg_flag_number  \\\n",
       "0                     0                0                1                0   \n",
       "1                     0                0                1                0   \n",
       "2                     0                0                1                0   \n",
       "3                     0                0                1                0   \n",
       "4                     0                0                1                0   \n",
       "...                 ...              ...              ...              ...   \n",
       "115067                1                0                1                0   \n",
       "115068                0                0                0                0   \n",
       "115069                0                0                0                0   \n",
       "115070                1                0                1                0   \n",
       "115071                0                0                0                0   \n",
       "\n",
       "        ece_flag_number  cwr_flag_number  ack_count  syn_count  fin_count  \\\n",
       "0                     0                0          0          0          0   \n",
       "1                     0                0          0          2          0   \n",
       "2                     0                0          0          2          0   \n",
       "3                     0                0          1          2          0   \n",
       "4                     0                0          2          2          0   \n",
       "...                 ...              ...        ...        ...        ...   \n",
       "115067                0                0          0          2          1   \n",
       "115068                0                0          0          0          0   \n",
       "115069                0                0          0          0          0   \n",
       "115070                0                0          0          2          1   \n",
       "115071                0                0          0          0          0   \n",
       "\n",
       "        urg_count  rst_count  CoAP  HTTP  HTTPS  DNS  Telnet  SMTP  SSH  IRC  \\\n",
       "0               1          2     0     1      0    0       0     0    0    0   \n",
       "1               4         14     0     0      1    0       0     0    0    0   \n",
       "2               7         28     0     0      1    0       0     0    0    0   \n",
       "3               2          7     0     1      0    0       0     0    0    0   \n",
       "4               2          9     0     1      0    0       0     0    0    0   \n",
       "...           ...        ...   ...   ...    ...  ...     ...   ...  ...  ...   \n",
       "115067          0          3     0     1      0    0       0     0    0    0   \n",
       "115068          0          0     0     0      0    1       0     0    0    0   \n",
       "115069          0          0     0     0      0    1       0     0    0    0   \n",
       "115070          0          3     0     1      0    0       0     0    0    0   \n",
       "115071          0          0     0     0      0    0       0     0    0    0   \n",
       "\n",
       "        TCP  UDP  DHCP  ARP  ICMP  IGMP  IPv  LLC  Tot sum  Min   Max  \\\n",
       "0         1    0     0    0     0     0    1    1     1501   54   778   \n",
       "1         1    0     0    0     0     0    1    1     4151   54  1506   \n",
       "2         1    0     0    0     0     0    1    1     5942   54  1506   \n",
       "3         1    0     0    0     0     0    1    1     6391   54  1506   \n",
       "4         1    0     0    0     0     0    1    1     6553   54  1506   \n",
       "...     ...  ...   ...  ...   ...   ...  ...  ...      ...  ...   ...   \n",
       "115067    1    0     0    0     0     0    1    1       66   66    66   \n",
       "115068    0    1     0    0     0     0    1    1      152   66    86   \n",
       "115069    0    1     0    0     0     0    1    1     1460   60   436   \n",
       "115070    1    0     0    0     0     0    1    1     2192   60   436   \n",
       "115071    0    1     0    0     0     0    1    1     3861   60   446   \n",
       "\n",
       "               AVG         Std  Tot size       IAT  Number   Magnitue  \\\n",
       "0       187.625000  234.260505        54  0.000193       8  19.371371   \n",
       "1       319.307692  502.889709      1506  0.582391      13  25.182335   \n",
       "2       848.857143  692.984318      1506  0.000132       7  38.716921   \n",
       "3       532.583333  649.853376        54  0.001591      12  35.448554   \n",
       "4       436.866667  611.959352        54  0.000684      15  30.470126   \n",
       "...            ...         ...       ...       ...     ...        ...   \n",
       "115067   66.000000    0.000000        66  0.000071       1   8.124038   \n",
       "115068   76.000000   10.000000        86  0.002155       2   8.717798   \n",
       "115069  146.000000  144.706600        86  0.000656      10  15.099669   \n",
       "115070  199.272727  155.298007        66  0.000100      11  16.905620   \n",
       "115071  227.117647  162.810927       444  0.102268      17  18.665476   \n",
       "\n",
       "            Radius    Covariance   Variance  Weight  DS status  Fragments  \\\n",
       "0       321.382074 -14259.875000  11.639548      16          0          0   \n",
       "1       710.282604   -190.050000   1.019383      40          0          0   \n",
       "2       105.655099      0.000000   0.000000      12          0          0   \n",
       "3       493.924529      0.000000   0.000000      35          0          0   \n",
       "4       665.957497      0.000000   0.000000      56          0          0   \n",
       "...            ...           ...        ...     ...        ...        ...   \n",
       "115067    0.000000      0.000000   0.000000       0          0          0   \n",
       "115068   10.000000      0.000000   0.000000       0          0          0   \n",
       "115069  150.421630      0.000000   0.000000       9          0          0   \n",
       "115070  157.489555      0.000000   0.000000      10          0          0   \n",
       "115071  169.177737   -653.066667  28.782629      30          0          0   \n",
       "\n",
       "        Sequence number  flow_idle_time  flow_active_time     Label  \n",
       "0                     0    1.928810e-04          0.000193  0_normal  \n",
       "1                     0    8.030751e-01          1.298898  0_normal  \n",
       "2                     0    1.320840e-04          1.308947  0_normal  \n",
       "3                     0    1.267583e+00          1.427035  0_normal  \n",
       "4                     0    7.359980e-04          1.480285  0_normal  \n",
       "...                 ...             ...               ...       ...  \n",
       "115067                0    7.100000e-05          0.002669       TCP  \n",
       "115068                0    1.716628e+09          0.000000       UDP  \n",
       "115069                0    1.716628e+09          0.000000       UDP  \n",
       "115070                0    9.990000e-05          0.001351       TCP  \n",
       "115071                0    1.022680e-01          0.715423  0_normal  \n",
       "\n",
       "[115072 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/custom_data_sub100k.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDCqKctrHfP8",
    "outputId": "c0e845f2-415d-4659-bd97-7ef88c07ab7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115072 entries, 0 to 115071\n",
      "Data columns (total 56 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   flow_duration     115072 non-null  float64\n",
      " 1   flow_byte         115072 non-null  int64  \n",
      " 2   src_port          115072 non-null  int64  \n",
      " 3   dst_port          115072 non-null  int64  \n",
      " 4   Duration          115072 non-null  int64  \n",
      " 5   Rate              115072 non-null  float64\n",
      " 6   Srate             115072 non-null  float64\n",
      " 7   Drate             115072 non-null  int64  \n",
      " 8   fin_flag_number   115072 non-null  int64  \n",
      " 9   syn_flag_number   115072 non-null  int64  \n",
      " 10  rst_flag_number   115072 non-null  int64  \n",
      " 11  psh_flag_number   115072 non-null  int64  \n",
      " 12  ack_flag_number   115072 non-null  int64  \n",
      " 13  urg_flag_number   115072 non-null  int64  \n",
      " 14  ece_flag_number   115072 non-null  int64  \n",
      " 15  cwr_flag_number   115072 non-null  int64  \n",
      " 16  ack_count         115072 non-null  int64  \n",
      " 17  syn_count         115072 non-null  int64  \n",
      " 18  fin_count         115072 non-null  int64  \n",
      " 19  urg_count         115072 non-null  int64  \n",
      " 20  rst_count         115072 non-null  int64  \n",
      " 21  CoAP              115072 non-null  int64  \n",
      " 22  HTTP              115072 non-null  int64  \n",
      " 23  HTTPS             115072 non-null  int64  \n",
      " 24  DNS               115072 non-null  int64  \n",
      " 25  Telnet            115072 non-null  int64  \n",
      " 26  SMTP              115072 non-null  int64  \n",
      " 27  SSH               115072 non-null  int64  \n",
      " 28  IRC               115072 non-null  int64  \n",
      " 29  TCP               115072 non-null  int64  \n",
      " 30  UDP               115072 non-null  int64  \n",
      " 31  DHCP              115072 non-null  int64  \n",
      " 32  ARP               115072 non-null  int64  \n",
      " 33  ICMP              115072 non-null  int64  \n",
      " 34  IGMP              115072 non-null  int64  \n",
      " 35  IPv               115072 non-null  int64  \n",
      " 36  LLC               115072 non-null  int64  \n",
      " 37  Tot sum           115072 non-null  int64  \n",
      " 38  Min               115072 non-null  int64  \n",
      " 39  Max               115072 non-null  int64  \n",
      " 40  AVG               115072 non-null  float64\n",
      " 41  Std               115072 non-null  float64\n",
      " 42  Tot size          115072 non-null  int64  \n",
      " 43  IAT               115072 non-null  float64\n",
      " 44  Number            115072 non-null  int64  \n",
      " 45  Magnitue          115072 non-null  float64\n",
      " 46  Radius            115072 non-null  float64\n",
      " 47  Covariance        115072 non-null  float64\n",
      " 48  Variance          115072 non-null  float64\n",
      " 49  Weight            115072 non-null  int64  \n",
      " 50  DS status         115072 non-null  int64  \n",
      " 51  Fragments         115072 non-null  int64  \n",
      " 52  Sequence number   115072 non-null  int64  \n",
      " 53  flow_idle_time    115072 non-null  float64\n",
      " 54  flow_active_time  115072 non-null  float64\n",
      " 55  Label             115072 non-null  object \n",
      "dtypes: float64(12), int64(43), object(1)\n",
      "memory usage: 49.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85P62UUrIOUr",
    "outputId": "c6f8cf90-631d-48eb-94e7-ddc6a4037648"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0_normal    36163\n",
       "TCP         25814\n",
       "UDP         21135\n",
       "ICMP        17673\n",
       "ARP         14287\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "QXqAncoEY79n",
    "outputId": "339ba316-3c5e-4595-ba93-fffb8a2a580e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc = {'figure.figsize' : (10, 7)})\n",
    "ax = sns.countplot(x = 'Label', data = df)\n",
    "ax.set(xlabel = 'Type', ylabel = 'Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5a4bc1d"
   },
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bf83c94b"
   },
   "outputs": [],
   "source": [
    "def remove_outliers_lof(X_data, y_data, contamination=0.05, random_seed=None):\n",
    "    \"\"\"\n",
    "    Remove outliers from a dataset using Local Outlier Factor (LOF).\n",
    "\n",
    "    Parameters:\n",
    "    - X_data: numpy array, feature matrix\n",
    "    - y_data: numpy array, label array\n",
    "    - contamination: float, the proportion of outliers in the dataset\n",
    "    - random_seed: int or None, seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - X_no_outliers: numpy array, feature matrix without outliers\n",
    "    - y_no_outliers: numpy array, label array without outliers\n",
    "    \"\"\"\n",
    "\n",
    "    unique_classes = np.unique(y_data)\n",
    "\n",
    "    X_no_outliers = np.empty((0, X_data.shape[1]), dtype=X_data.dtype)\n",
    "    y_no_outliers = np.empty(0, dtype=y_data.dtype)\n",
    "\n",
    "    for label in unique_classes:\n",
    "        # Select samples belonging to the current class\n",
    "        # print(label)\n",
    "        class_mask = (y_data == label)\n",
    "        X_class = X_data[class_mask]\n",
    "        if label == 0:\n",
    "            X_no_outliers = np.vstack((X_no_outliers, X_class))\n",
    "            y_no_outliers = np.concatenate((y_no_outliers, y_data[class_mask]))\n",
    "        else:\n",
    "            # Apply LOF to detect outliers\n",
    "            lof = LocalOutlierFactor(contamination=contamination)\n",
    "            outliers_mask = lof.fit_predict(X_class) == -1\n",
    "\n",
    "            # Remove outliers from the current class\n",
    "            X_no_outliers = np.vstack((X_no_outliers, X_class[~outliers_mask]))\n",
    "            y_no_outliers = np.concatenate((y_no_outliers, y_data[class_mask][~outliers_mask]))\n",
    "\n",
    "    return X_no_outliers, y_no_outliers\n",
    "\n",
    "def prepare_data(data, target, cls_drop):\n",
    "    classes = np.unique(target)\n",
    "    if __MODE == \"Novelty_multi\":\n",
    "        mask = ~np.isin(classes, cls_drop)\n",
    "        known = classes[mask]\n",
    "    elif __MODE == \"1_Cls\":\n",
    "        known = \"0_normal\"\n",
    "    else:\n",
    "        known = classes\n",
    "\n",
    "\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.3, stratify = target, random_state=__SEED)\n",
    "\n",
    "\n",
    "    # Loáº¡i bá» cÃ¡c class khÃ´ng biáº¿t trong táº­p train\n",
    "    mask = np.array([y in known for y in target_train])\n",
    "\n",
    "    X_train = data_train[mask]\n",
    "    y_train = target_train[mask]\n",
    "\n",
    "    idx = y_train.argsort()\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    X_test = data_test\n",
    "    y_labels = target_test\n",
    "\n",
    "    if __MODE == \"Novelty_multi\":\n",
    "        # Test labels are 1 if novel, otherwise 0.\n",
    "        # y_test_bina = np.array([1 if cl not in known else 0 for cl in y_labels])\n",
    "        y_test = np.array([-1 if cl not in known else encoder.transform([cl])[0] for cl in y_labels])\n",
    "        # y_test = np.array([cl+\"-1\" if cl not in known else cl for cl in y_labels])\n",
    "\n",
    "\n",
    "    if __MODE == \"Supervise\":\n",
    "        # y_test_bina = np.array([1 if cl != 0 else 0 for cl in y_labels])\n",
    "\n",
    "        y_test = encoder.transform(y_labels)\n",
    "\n",
    "    if __MODE == \"1_Cls\":\n",
    "        y_test = np.array([1 if cl not in known else encoder.transform([cl])[0] for cl in y_labels])\n",
    "\n",
    "    # encoder = LabelEncoder()\n",
    "    # y_test = encoder.fit_transform(y_test)\n",
    "    # y_train = encoder.transform(y_train)\n",
    "    classes = np.unique(y_train)\n",
    "\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, classes, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "29031472"
   },
   "outputs": [],
   "source": [
    "def Get_Scaler(name):\n",
    "  # (StandardScaler, MinMaxScaler, RobustScaler, Normalizer)\n",
    "  if name == \"StandardScaler\":\n",
    "    return StandardScaler()\n",
    "  if name == \"MinMaxScaler\":\n",
    "    return MinMaxScaler()\n",
    "  if name == \"RobustScaler\":\n",
    "    return RobustScaler()\n",
    "  if name == \"Normalizer\":\n",
    "    return Normalizer()\n",
    "  if name == \"QuantileTransformer\":\n",
    "      return QuantileTransformer(output_distribution = \"normal\", random_state=__SEED)\n",
    "  return None\n",
    "\n",
    "def preprocess_data(drop_cls, data):\n",
    "    datasets = data.to_numpy()\n",
    "    labels = datasets[:,-1]\n",
    "    dataset = datasets[:,:-1]\n",
    "\n",
    "\n",
    "    ## ========================== Running Main Model ================================================\n",
    "\n",
    "    X_train, y_train, X_test, y_test, classes_tmp, encoder = prepare_data(dataset, labels, drop_cls)\n",
    "\n",
    "    # print(f\"X_train shape: {X_train.shape}\")\n",
    "    # print(f\"y_train counts: {np.unique(y_train, return_counts=True)}\")\n",
    "\n",
    "    # X_train, y_train = reduce_trainning_data(X_train, y_train)\n",
    "\n",
    "\n",
    "    ## ========================== Scaler data ================================================\n",
    "    scaler = Get_Scaler(name=__SCALER)\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    # LÆ°u scaler vÃ o tá»‡p\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "    # Remove outliers\n",
    "    X_train, y_train= remove_outliers_lof(X_train, y_train)\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train counts: {np.unique(y_train, return_counts=True)}\")\n",
    "\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_test counts: {np.unique(y_test, return_counts=True)}\")\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, classes_tmp, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uc3k8eRaIQYU"
   },
   "source": [
    "# INNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd322d4a"
   },
   "source": [
    "### INNR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "d3b4e81d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def K(X,Y=None,metric='poly',coef0=1,gamma=None,degree=3):\n",
    "    if metric == 'poly':\n",
    "        k = pairwise_kernels(X,Y=Y,metric=metric,coef0=coef0,gamma=gamma,degree=degree)\n",
    "    elif metric == 'linear':\n",
    "        k = pairwise_kernels(X,Y=Y,metric=metric)\n",
    "    elif metric == 'sigmoid':\n",
    "        k = pairwise_kernels(X,Y=Y,metric=metric,coef0=coef0,gamma=gamma)\n",
    "    elif metric == 'rbf':\n",
    "        k = pairwise_kernels(X,Y=Y,metric=metric,gamma=gamma)\n",
    "    return k\n",
    "\n",
    "def kernel_distance_matrix(matrix1 = None, matrix2 = None, kernel=None, gamma=None):\n",
    "    \"\"\"\n",
    "    Calculate the distance between two matrices using the kernel trick.\n",
    "    Parameters:\n",
    "    - matrix1: The first input matrix (NumPy array).\n",
    "    - matrix2: The second input matrix (NumPy array).\n",
    "    - gamma: The gamma parameter for the RBF kernel.\n",
    "    Returns:\n",
    "    - distance_matrix: The distance matrix between the two input matrices.\n",
    "    \"\"\"\n",
    "\n",
    "    if matrix1.shape[1] != matrix2.shape[1]:\n",
    "        raise ValueError(\"The number of features in the input matrices must be the same.\")\n",
    "    Kaa = []\n",
    "    for i in range(len(matrix1)):\n",
    "        Kaa.append(K(matrix1[i,:].reshape(1,-1),metric=kernel))\n",
    "    Kaa = np.asarray(Kaa).ravel().reshape(len(Kaa),1)\n",
    "    Kab = K(matrix1,matrix2,metric=kernel)\n",
    "    Kbb = []\n",
    "    for i in range(len(matrix2)):\n",
    "        Kbb.append(K(matrix2[i,:].reshape(1,-1),metric=kernel))\n",
    "    Kbb = np.asarray(Kbb).ravel()\n",
    "    d = Kaa-2*Kab+Kbb #shape: (matrix1,matrix2)\n",
    "    return d\n",
    "\n",
    "def calculate_accuracy_for_label(y_true, y_predict, label):\n",
    "    \"\"\"\n",
    "    Calculate accuracy for a specific label.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: The true labels (1D NumPy array).\n",
    "    - y_predict: The predicted labels (1D NumPy array).\n",
    "    - label: The specific label for which to calculate accuracy.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: The accuracy for the specified label.\n",
    "    \"\"\"\n",
    "    # Create a boolean mask for the specified label\n",
    "    mask = (y_true == label)\n",
    "\n",
    "    # Extract true labels and predicted labels for the specified label\n",
    "    true_labels_for_label = y_true[mask]\n",
    "    predicted_labels_for_label = y_predict[mask]\n",
    "\n",
    "\n",
    "    # Calculate accuracy for the specified label\n",
    "    accuracy = np.mean(true_labels_for_label == predicted_labels_for_label)\n",
    "    # print(accuracy)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "class kINN:\n",
    "    def __init__(self, R=1, kernel=\"linear\", mode = \"Supervise\"):\n",
    "        self.R = R\n",
    "        self.kernel = kernel\n",
    "        self.distance_matrix = None\n",
    "        self.cluster_labels = None\n",
    "        self.cluster_map = None\n",
    "        self.N = None\n",
    "        # self.n_clusters = n_clusters\n",
    "        self.X = None\n",
    "        self.M = None\n",
    "        self.is_fit = False\n",
    "        self.DNN_test = None\n",
    "        self.distance_matrix_test = None\n",
    "        self.mode = mode\n",
    "\n",
    "\n",
    "\n",
    "    def _Bruteforce_threshold(self, y_test, y_pred, scores):\n",
    "        # d = Decimal(np.min(scores))\n",
    "        # min_th = max(1e-8,pow(10, d.as_tuple().exponent))\n",
    "        # d = Decimal(np.max(scores))\n",
    "        # max_th = min(1e-2,pow(10, d.as_tuple().exponent))\n",
    "\n",
    "        # print(\"======================= DEBUG =======================\")\n",
    "        # print(min_th, max_th)\n",
    "        # print(\"======================= DEBUG =======================\")\n",
    "        min_th = 1e-7\n",
    "        max_th = 1e-1\n",
    "        # __step = int(max_th / min_th)\n",
    "        __step = 10000\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        mcc = 0\n",
    "        ndr = 0\n",
    "        y_pred_adv = y_pred\n",
    "\n",
    "\n",
    "        __rag = np.unique(y_test)\n",
    "        thr = -np.ones(len(__rag))\n",
    "\n",
    "        for id in __rag[1:]:\n",
    "            # print(\"DEBUG:\", id)\n",
    "            for x in np.linspace(min_th, max_th, num=__step):\n",
    "                y_pred_adv_tmp = np.array([-1 if (y_p == id) and (sc > x) else y_p for y_p, sc in zip( y_pred,scores)])\n",
    "                mcc_tmp = matthews_corrcoef(y_test, y_pred_adv_tmp)\n",
    "                ndr_tmp = calculate_accuracy_for_label(y_test, y_pred_adv_tmp, -1)\n",
    "                if np.mean([mcc_tmp*2,ndr_tmp]) > np.mean([mcc*2,ndr]):\n",
    "                    y_pred_adv = y_pred_adv_tmp\n",
    "                    mcc = mcc_tmp\n",
    "                    ndr = ndr_tmp\n",
    "                    thr[id] = x\n",
    "            y_pred = y_pred_adv\n",
    "        print(\"DEBUG - update mcc:\", mcc, ndr, thr)\n",
    "        return y_pred_adv, mcc, thr\n",
    "\n",
    "\n",
    "    def _Bruteforce_threshold_1_cls(self, y_test, y_pred, scores):\n",
    "          # d = Decimal(np.min(scores))\n",
    "          # min_th = max(1e-8,pow(10, d.as_tuple().exponent))\n",
    "          # d = Decimal(np.max(scores))\n",
    "          # max_th = min(1e-2,pow(10, d.as_tuple().exponent))\n",
    "\n",
    "          # print(\"======================= DEBUG =======================\")\n",
    "          # print(min_th, max_th)\n",
    "          # print(\"======================= DEBUG =======================\")\n",
    "          min_th = 1e-7\n",
    "          max_th = 1e-1\n",
    "          # __step = int(max_th / min_th)\n",
    "          __step = 10000\n",
    "          mcc = matthews_corrcoef(y_test, y_pred)\n",
    "          mcc = 0\n",
    "          ndr = 0\n",
    "          y_pred_adv = y_pred\n",
    "\n",
    "\n",
    "          __rag = np.unique(y_test)\n",
    "          thr = -np.ones(len(__rag))\n",
    "\n",
    "\n",
    "          # for id in __rag[0]:\n",
    "          id = 0\n",
    "          for x in np.linspace(min_th, max_th, num=__step):\n",
    "              y_pred_adv_tmp = np.array([1 if (y_p == id) and (sc > x) else y_p for y_p, sc in zip( y_pred,scores)])\n",
    "              mcc_tmp = matthews_corrcoef(y_test, y_pred_adv_tmp)\n",
    "              ndr_tmp = calculate_accuracy_for_label(y_test, y_pred_adv_tmp, 1)\n",
    "              if np.mean([mcc_tmp*2,ndr_tmp]) > np.mean([mcc*2,ndr]):\n",
    "                  y_pred_adv = y_pred_adv_tmp\n",
    "                  mcc = mcc_tmp\n",
    "                  ndr = ndr_tmp\n",
    "                  thr[id] = x\n",
    "          y_pred = y_pred_adv\n",
    "\n",
    "\n",
    "          print(\"DEBUG - update mcc:\", mcc, ndr, thr)\n",
    "          return y_pred_adv, mcc, thr\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, X, y = None, single = False, type = \"distance\"):\n",
    "        \"\"\"\n",
    "        Fit the kINN model to the input data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data, a 2D numpy array where each row represents a sample.\n",
    "        - y: Input label, a array where each row represents a label for corresponding label\n",
    "        - type: the strategy to calculate distance, support:\n",
    "                                                            + \"distance\" - use only distance\n",
    "                                                            + \"density\" - use LOF score as weight when calculate distance\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        if (y is None) and (self.mode == \"1_Cls\"):\n",
    "          # -np.ones(self.N, dtype=int)\n",
    "          y = np.zeros(X.shape[0], dtype=int)\n",
    "        self._fit_classify(X,y,type)\n",
    "        self.is_fit = True\n",
    "        if single == True:\n",
    "            X_new = self.__map_to_single_point(X)\n",
    "\n",
    "            return X_new, self.cluster_labels, self.cluster_map\n",
    "        else:\n",
    "            return self.cluster_labels, self.cluster_map\n",
    "\n",
    "\n",
    "    def _calculate_lof(self, dis_mat, k_dis, d_nn, N_cnt):\n",
    "        # calculate reachability distance\n",
    "\n",
    "        re_dis_k = np.array([ [ max(dis_mat[i,k],k_dis[k]) for k in range(N_cnt) ] for i in range(N_cnt)])\n",
    "\n",
    "        # calculate Local Reachability Density (LRD)\n",
    "\n",
    "        lrd = np.array([1. / np.mean(re_dis_k[x, d_nn[x]]) for x in range(N_cnt)])\n",
    "\n",
    "        # calculate LOF\n",
    "        lof = np.array([np.mean(lrd[d_nn[x]]) / lrd[x] for x in range(N_cnt)])\n",
    "\n",
    "        return lof\n",
    "\n",
    "    def _fit_classify(self, X, y, type=\"distance\"):\n",
    "        N = X.shape[0]\n",
    "    \n",
    "        D_NN = np.empty((N,), dtype=object)\n",
    "        INNR = np.empty((N,), dtype=object)\n",
    "    \n",
    "        classes, cls_cnt = np.unique(y, return_counts=True)\n",
    "    \n",
    "        for cls, N_cnt in zip(classes, cls_cnt):\n",
    "            indicates = np.asarray(y == cls).nonzero()[0]\n",
    "            X_cls = X[indicates]\n",
    "            y_cls = y[indicates]\n",
    "    \n",
    "            dis_mat = kernel_distance_matrix(matrix1=X_cls, matrix2=X_cls, kernel=self.kernel)\n",
    "    \n",
    "            if type == \"density\":\n",
    "                k_dis = -np.ones(N_cnt, dtype=float)\n",
    "                d_nn = np.empty((N_cnt,), dtype=object)\n",
    "                re_dis_k = -np.ones((N_cnt, N_cnt), dtype=float)\n",
    "    \n",
    "                for i in range(N_cnt):\n",
    "                    dis_mat[i, i] = 0\n",
    "                    tmp = dis_mat[i, :].argsort()\n",
    "    \n",
    "                    # Some case that 2 point are too close\n",
    "                    dnn_tmp = [i]\n",
    "                    cnt = 0\n",
    "                    for x in tmp:\n",
    "                        if abs(dis_mat[i, dnn_tmp[-1]] - dis_mat[i, x]) > 1e-9:\n",
    "                            dnn_tmp.append(x)\n",
    "                            cnt += 1\n",
    "                            k_dis[i] = dis_mat[i, x]\n",
    "                        else:\n",
    "                            dnn_tmp.append(x)\n",
    "    \n",
    "                        if cnt >= self.R:\n",
    "                            break\n",
    "                    d_nn[i] = np.array(dnn_tmp[1:])\n",
    "    \n",
    "                lof = self._calculate_lof(dis_mat, k_dis, d_nn, N_cnt)\n",
    "    \n",
    "                # Update new matrix\n",
    "                dis_mat = np.array([[dis_mat[i, k] * lof[k] for k in range(N_cnt)] for i in range(N_cnt)])\n",
    "    \n",
    "            # calculate D_N\n",
    "            for i in range(N_cnt):\n",
    "                dis_mat[i, i] = 0\n",
    "                tmp = dis_mat[i, :].argsort()\n",
    "    \n",
    "                id = indicates[i]\n",
    "                D_NN[id] = np.array(indicates[tmp])\n",
    "    \n",
    "                # Some case that 2 point are too close\n",
    "                dnn_tmp = [i]\n",
    "                cnt = 0\n",
    "                for x in tmp:\n",
    "                    if abs(dis_mat[i, dnn_tmp[-1]] - dis_mat[i, x]) > 1e-9:\n",
    "                        dnn_tmp.append(x)\n",
    "                        cnt += 1\n",
    "                    else:\n",
    "                        dnn_tmp.append(x)\n",
    "    \n",
    "                    if cnt >= self.R:\n",
    "                        break\n",
    "    \n",
    "                D_NN[id] = np.array(indicates[dnn_tmp[1:]])\n",
    "    \n",
    "            self.D_NN = D_NN\n",
    "    \n",
    "            for i in tqdm(indicates, desc=f\"Processing class {cls}\"):\n",
    "                NN = D_NN[i]\n",
    "                tmp = []\n",
    "                for p in NN:\n",
    "                    p_near_neighbor = D_NN[p]\n",
    "                    if i in p_near_neighbor:\n",
    "                        tmp.append(p)\n",
    "    \n",
    "                pair = (i, tmp)\n",
    "                INNR[i] = pair\n",
    "    \n",
    "        self.INNR = INNR\n",
    "        self.N = N\n",
    "        self.cluster_labels, self.no_cluser = self._label_clusters()\n",
    "    \n",
    "        cluster_map = np.full(self.no_cluser, -1)\n",
    "    \n",
    "        for x_tmp, y_tmp in zip(self.cluster_labels, y):\n",
    "            if cluster_map[x_tmp] == -1:\n",
    "                cluster_map[x_tmp] = y_tmp\n",
    "            else:\n",
    "                if cluster_map[x_tmp] != y_tmp:\n",
    "                    print(\"Debug - Loi KNN\")\n",
    "    \n",
    "        self.cluster_map = cluster_map\n",
    "\n",
    "\n",
    "    # def _fit_cluster(self,X):\n",
    "    #     N = X.shape[0]\n",
    "    #     dis_mat = kernel_distance_matrix(matrix1 = X, matrix2 = X, kernel = self.kernel)\n",
    "    #     D_NN = []\n",
    "    #     for i in range(N):\n",
    "    #         dis_mat[i,i] = 0\n",
    "    #         tmp = dis_mat[i,].argsort()\n",
    "    #         D_NN.append(tmp)\n",
    "\n",
    "    #     D_NN = np.array(D_NN)\n",
    "    #     self.D_NN = D_NN\n",
    "    #     INNR = []\n",
    "\n",
    "    #     for i in range(N):\n",
    "    #         NN = D_NN[i, 1:self.R+1]\n",
    "\n",
    "        #     tmp = []\n",
    "        #     for p in NN:\n",
    "        #         p_near_neighbor = D_NN[p, 1:self.R+1]\n",
    "        #         if i in p_near_neighbor:\n",
    "        #             tmp.append(p)\n",
    "\n",
    "        #     pair = (i, tmp)\n",
    "        #     INNR.append(pair)\n",
    "        # self.INNR = INNR\n",
    "\n",
    "        # self.N = N\n",
    "        # self.cluster_labels, self.no_cluser = self._label_clusters()\n",
    "\n",
    "    def _label_clusters(self):\n",
    "        \"\"\"\n",
    "        Label clusters using deep find search (DFS) algorithm.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data, a 2D numpy array where each row represents a sample.\n",
    "\n",
    "        Returns:\n",
    "        - labels: A numpy array containing cluster labels for each sample.\n",
    "\n",
    "        \"\"\"\n",
    "        # print(self.INN)\n",
    "        labels = -np.ones(self.N, dtype=int)\n",
    "        current_label = 0\n",
    "\n",
    "        # INNR = sorted(self.INNR,key=lambda x: len(x[1]), reverse=True)\n",
    "        for x in self.INNR:\n",
    "            id = x[0]\n",
    "            if labels[id] == -1:\n",
    "                queue = [id]\n",
    "                labels[id] = current_label\n",
    "                # _debug = 0\n",
    "                for q in queue:\n",
    "                    neighbors = self.INNR[q][1]\n",
    "                    for neighbor in neighbors:\n",
    "                        if labels[neighbor] == -1:\n",
    "                            queue.append(neighbor)\n",
    "                            labels[neighbor] = current_label\n",
    "                current_label += 1\n",
    "        return labels, current_label\n",
    "\n",
    "    def _dfs_label_clusters(self, i, current_label, labels):\n",
    "        \"\"\"\n",
    "        DFS algorithm to label clusters.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data, a 2D numpy array where each row represents a sample.\n",
    "        - i: Index of the current sample being explored.\n",
    "        - current_label: Current cluster label.\n",
    "        - labels: A numpy array containing cluster labels for each sample.\n",
    "\n",
    "        \"\"\"\n",
    "        if labels[i] != -1:\n",
    "            return\n",
    "\n",
    "        labels[i] = current_label\n",
    "\n",
    "        neighbors = self.INNR[i][1]\n",
    "        for neighbor in neighbors:\n",
    "            #\n",
    "            self._dfs_label_clusters(neighbor, current_label, labels)\n",
    "\n",
    "    def __map_to_single_point(self, X):\n",
    "\n",
    "        a = self.cluster_labels\n",
    "        x_new = []\n",
    "        a_new = []\n",
    "        for cl in np.unique(a):\n",
    "            mask = np.isin(a, cl)\n",
    "            known = X[mask]\n",
    "            a_new.append(self.cluster_map[cl])\n",
    "        # print(x_new)\n",
    "        # print(a_new)\n",
    "        self.cluster_labels = np.array(a_new)\n",
    "\n",
    "\n",
    "        return np.array(x_new)\n",
    "\n",
    "    def find_nearest_neighbors(self, X, x_i):\n",
    "        \"\"\"\n",
    "        Find the R nearest neighbors of x_i using kernel trick.\n",
    "\n",
    "        Parameters:\n",
    "        - x_i: The input sample.\n",
    "\n",
    "        Returns:\n",
    "        - neighbors: A set of R nearest neighbors for x_i.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.distance_matrix is None:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "\n",
    "        # Calculate kernel vector\n",
    "        kernel_vector = self.distance_matrix[x_i].flatten()\n",
    "\n",
    "        # Get indices of R nearest neighbors\n",
    "        nearest_indices = np.argsort(kernel_vector)[1:self.R+1]\n",
    "\n",
    "        return set(nearest_indices)\n",
    "\n",
    "\n",
    "    def predict(self, X_test, y = None):\n",
    "        \"\"\"\n",
    "        Predict the cluster labels for the input samples.\n",
    "\n",
    "        Parameters:\n",
    "        - X_test: Input data, a 2D numpy array where each row represents a sample.\n",
    "\n",
    "        Returns:\n",
    "        - predicted_labels: A numpy array containing predicted cluster labels for each sample.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.is_fit == False:\n",
    "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
    "\n",
    "\n",
    "        N_test = X_test.shape[0]\n",
    "        self.M = N_test\n",
    "        dis_mat_X_test = kernel_distance_matrix(matrix1 = X_test, matrix2 = self.X, kernel = self.kernel)\n",
    "        self.distance_matrix_test = dis_mat_X_test\n",
    "        D_NN_test = []\n",
    "        # print(\"Khoáº£ng cÃ¡ch X_test -> X_train:\\n \",dis_mat_X_test,\"\\n\")\n",
    "        for i in range(N_test):\n",
    "            # dis_mat_X_test[i,i] = 0\n",
    "            tmp = dis_mat_X_test[i,].argsort()\n",
    "            D_NN_test.append(tmp)\n",
    "\n",
    "        D_NN_test = np.array(D_NN_test)\n",
    "        # print(D_NN_test.shape)\n",
    "        self.D_NN_test = D_NN_test\n",
    "        INNR_X_test = []\n",
    "        # TÃ¬m INNR_X_test\n",
    "        for i in range(N_test):\n",
    "            NN = D_NN_test[i, 1:self.R+1]\n",
    "            # print(NN)\n",
    "            tmp = []\n",
    "            for p in NN:\n",
    "                p_near_neighbor = D_NN_test.T[p, 1:self.R+1]\n",
    "                # print(\"neighbor: \",p_near_neighbor)\n",
    "                if i in p_near_neighbor:\n",
    "                    # print(p_near_neighbor)\n",
    "                    tmp.append(p)\n",
    "            pair = (i, tmp)\n",
    "            # print(pair)\n",
    "            INNR_X_test.append(pair)\n",
    "        self.INNR_test = INNR_X_test\n",
    "\n",
    "\n",
    "        if self.mode == \"Supervise\":\n",
    "            labels = self._predict_multi()\n",
    "            return labels\n",
    "        elif self.mode == \"Novelty_multi\":\n",
    "            labels,mcc, threshold  = self._predict_novelty(y)\n",
    "            return labels , mcc, threshold\n",
    "        else:\n",
    "            labels,mcc, threshold = self._predict_1Class(y)\n",
    "            return labels, mcc, threshold\n",
    "\n",
    "\n",
    "\n",
    "    def _predict_multi(self):\n",
    "        labels = -np.ones(self.M, dtype=int)\n",
    "        # c = 0\n",
    "        for pair in self.INNR_test:\n",
    "                idx = pair[0]\n",
    "                if pair[1] != []:  # Kiá»ƒm tra xem danh sÃ¡ch neighbor cÃ³ rá»—ng khÃ´ng\n",
    "                    neighbors = pair[1]\n",
    "                    # print(id, \"neigibor = \",neighbors)\n",
    "                    labels[idx] = self.cluster_map[self.cluster_labels[neighbors[0]]]\n",
    "                    # c+= 1\n",
    "                    # print(self.cluster_labels[neighbors[0]])\n",
    "                else:\n",
    "                    labels[idx] = self.cluster_map[self.cluster_labels[self.D_NN_test[idx][0]]]\n",
    "        # print(\"Count: \",c)\n",
    "        return labels\n",
    "\n",
    "\n",
    "    def _predict_novelty(self, y):\n",
    "        scores_mat = self.distance_matrix_test\n",
    "        y_pred = [self.cluster_labels[x] for x in np.argmin(scores_mat, axis=1)]\n",
    "\n",
    "        for i in range(self.M):\n",
    "            y_pred[i] = self.cluster_map[y_pred[i]]\n",
    "\n",
    "        scores = np.amin(scores_mat, axis=1)\n",
    "        y_pred_adv, mcc, threshold = self._Bruteforce_threshold(y, y_pred, scores)\n",
    "\n",
    "\n",
    "        print(f\"MCC: {mcc}\", f\"threshold: {threshold}\")\n",
    "\n",
    "        return y_pred_adv, mcc, threshold\n",
    "\n",
    "\n",
    "    def _predict_1Class(self,y):\n",
    "\n",
    "        scores_mat = self.distance_matrix_test\n",
    "        # print(scores_mat)\n",
    "        # y_pred = [self.cluster_labels[x] for x in np.argmin(scores_mat, axis=1)]\n",
    "\n",
    "        # for i in range(self.M):\n",
    "        #     y_pred[i] = self.cluster_map[y_pred[i]]\n",
    "        y_pred = np.zeros(self.M, dtype = int)\n",
    "        scores = np.amin(scores_mat, axis=1)\n",
    "        y_pred_adv, mcc, threshold = self._Bruteforce_threshold_1_cls(y, y_pred, scores)\n",
    "        # print(\"DEBUG- y_pred: \", y_pred)\n",
    "\n",
    "        print(f\"MCC: {mcc}\", f\"threshold: {threshold}\")\n",
    "\n",
    "        return y_pred_adv, mcc, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2decca04"
   },
   "source": [
    "### INNR_evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": false,
    "id": "eb9192da"
   },
   "outputs": [],
   "source": [
    "# basic random seed\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "__CUSTOM_COLS=['MCC', 'ACC','TPR', 'FPR', 'F1', 'TPR macro','PPV macro','F1 macro',\"AUC\",\"Training time\",\"Testing time\"]\n",
    "__DEFAULT_RANDOM_SEED = 42\n",
    "\n",
    "def seedEverything(seed=__DEFAULT_RANDOM_SEED):\n",
    "  random.seed(seed)\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  np.random.seed(seed)\n",
    "\n",
    "  # # tensorflow random seed\n",
    "  # import tensorflow as tf\n",
    "  # tf.random.set_seed(seed)\n",
    "\n",
    "  # # torch random seed\n",
    "  # import torch\n",
    "  # torch.manual_seed(seed)\n",
    "  # torch.cuda.manual_seed(seed)\n",
    "  # torch.backends.cudnn.deterministic = True\n",
    "  # torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "\n",
    "def cfs_matrix(y_label, y_pred, labels):\n",
    "\n",
    "    cfs_mt = np.full((len(labels), len(labels)), 0)\n",
    "\n",
    "    for x,y in zip(y_label, y_pred):\n",
    "        cfs_mt[x,y] += 1\n",
    "\n",
    "    return cfs_mt\n",
    "\n",
    "def calc_index(testdf, Label_name, export_fig):\n",
    "\n",
    "  #     P\n",
    "  #     0   1\n",
    "  # T 0 TN FP\n",
    "  #   1 FN TP\n",
    "\n",
    "    # print(\"Debug\")\n",
    "    # print(np.unique(testdf.label))\n",
    "    # print(np.unique(testdf.y_pred))\n",
    "    cnf_matrix = confusion_matrix(testdf.label, testdf.y_pred, labels = np.unique(testdf.label))\n",
    "  #   # plot_confusion_matrix(\"Model_cfs\",cnf_matrix, target_names=Label_name,figsize = (20, 10), export_fig=export_fig)\n",
    "\n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "\n",
    "  #   if len(Label_name) == 2:\n",
    "  #       TN = cnf_matrix[0,0]\n",
    "  #       FP = cnf_matrix[0,1]\n",
    "  #       FN = cnf_matrix[1,0]\n",
    "  #       TP = cnf_matrix[1,1]\n",
    "\n",
    "  # # Sensitivity, hit rate, recall, or true positive rate\n",
    "  #   TPR = TP/(TP+FN) *100.\n",
    "  #   # Specificity or true negative rate\n",
    "  #   TNR = TN/(TN+FP) *100.\n",
    "  #   # Precision or positive predictive value\n",
    "  #   PPV = TP/(TP+FP) *100.\n",
    "  #   # Negative predictive value\n",
    "  #   NPV = TN/(TN+FN) *100.\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN) *100.\n",
    "  #   # False negative rate\n",
    "  #   FNR = FN/(TP+FN) *100.\n",
    "  #   # False discovery rate\n",
    "  #   FDR = FP/(TP+FP) *100.\n",
    "  #   # F1 Score\n",
    "  #   F1 = 2 * (PPV * TPR) / (PPV + TPR)\n",
    "\n",
    "  #   # Matthewâ€™s correlation coefficient\n",
    "  #   MCC = ((TP * TN) - (FP * FN)) / (( (TP+FP) * (TP+FN) * (TN+FP) * (TN+FN) ) ** 0.5)\n",
    "\n",
    "  #   # Overall accuracy\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN) *100.\n",
    "\n",
    "    auc_func = -1\n",
    "    # if len(Label_name) == 3:\n",
    "    #     false_positive_rate, true_positive_rate, thresholds = roc_curve(testdf.label,  testdf.y_pred)\n",
    "    #     auc_func = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "    tpr_func = recall_score(testdf.label,testdf.y_pred,average='macro', zero_division = 0) *100.\n",
    "    ppv_func = precision_score(testdf.label,testdf.y_pred,average='macro', zero_division = 0) *100.\n",
    "    f1_func = f1_score(testdf.label,testdf.y_pred,average='macro', zero_division = 0) *100.\n",
    "    mcc_func = matthews_corrcoef(testdf.label,testdf.y_pred)\n",
    "    # if len(Label_name) == 2:\n",
    "    #     print(\"------------------------\")\n",
    "    #     logger.info(\"ACC: {:.4f}\".format(ACC))\n",
    "    #     logger.info(\"MCC: {:.4f}\".format(MCC))\n",
    "    #     logger.info(\"TPR: {:.4f}\".format(TPR))\n",
    "    #     logger.info(\"PPV: {:.4f}\".format(PPV))\n",
    "    #     logger.info(\"FPR: {:.4f}\".format(FPR))\n",
    "    #     logger.info(\"F1 : {:.4f}\".format(F1))\n",
    "    # else:\n",
    "    ACC = sum(TP+TN)/(sum(TP+FP+FN+TN)) *100.\n",
    "    #     TPR = sum(TP)/sum((TP+FN)) *100.\n",
    "    #     PPV = sum(TP)/sum((TP+FP)) *100.\n",
    "    FPR = sum(FP)/sum((FP+TN)) *100.\n",
    "    #     F1  = 2 * (PPV * TPR) / (PPV + TPR)\n",
    "    #     print(\"------------------------\")\n",
    "    #     logger.info(\"ACC: {:.4f}\".format(ACC))\n",
    "    #     logger.info(\"TPR: {:.4f}\".format(TPR))\n",
    "    #     logger.info(\"PPV: {:.4f}\".format(PPV))\n",
    "    #     logger.info(\"FPR: {:.4f}\".format(FPR))\n",
    "    #     logger.info(\"F1 : {:.4f}\".format(F1))\n",
    "\n",
    "    print(\"TPR-macro: {:.4f}\".format(tpr_func))\n",
    "    print(\"FPR      : {:.4f}\".format(FPR))\n",
    "    print(\"PPV-macro: {:.4f}\".format(ppv_func))\n",
    "    print(\"F1-macro : {:.4f}\".format(f1_func))\n",
    "    print(\"MCC-func  : {:.4f}\".format(mcc_func))\n",
    "    print(\"AUC-func  : {:.4f}\".format(auc_func))\n",
    "    print(\"CFS MATRIX:\\n\",cnf_matrix)\n",
    "    return mcc_func, ACC, tpr_func, FPR, ppv_func, f1_func, auc_func, cnf_matrix\n",
    "\n",
    "def Average(lst):\n",
    "  return sum(lst) / len(lst)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(name,cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          figsize=(15,8),\n",
    "                          cmap=None,\n",
    "                          normalize=False,export_fig=None):\n",
    "\n",
    "  import matplotlib.pyplot as plt\n",
    "  import numpy as np\n",
    "  import itertools\n",
    "\n",
    "  accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "  misclass = 1 - accuracy\n",
    "\n",
    "  if cmap is None:\n",
    "    cmap = plt.get_cmap('Blues')\n",
    "  norm_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]*100\n",
    "  plt.figure(figsize=figsize)\n",
    "  plt.imshow(norm_cm, interpolation='nearest', cmap=cmap)\n",
    "  plt.colorbar()\n",
    "\n",
    "  if target_names is not None:\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45, fontsize='large')\n",
    "    plt.yticks(tick_marks, target_names, fontsize='large')\n",
    "\n",
    "  thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "  thresh= 50\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, \"{:,}\\n{:0.2f}%\".format(cm[i, j], norm_cm[i, j]),\n",
    "                horizontalalignment=\"center\",\n",
    "                verticalalignment=\"center\",\n",
    "                color=\"white\" if norm_cm[i, j] > thresh else \"black\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label', fontsize='x-large')\n",
    "  plt.xlabel('Predicted label', fontsize='x-large')\n",
    "\n",
    "  if export_fig is not None:\n",
    "    plt.savefig(os.path.join(export_fig,'cfs_matrix.png'), bbox_inches='tight')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "f901fda2"
   },
   "outputs": [],
   "source": [
    "def Model_evaluating(y_true, y_pred, __Label_use_name, export_fig = None):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    y_pred = np.array(y_pred)\n",
    "    emberdf = pd.DataFrame({\n",
    "        'y_pred': y_pred.astype(int),\n",
    "        'label': y_true.astype(int)})\n",
    "    # print(emberdf.label.unique())\n",
    "    # print(emberdf.y_pred.unique())\n",
    "    mcc, acc, tpr_func, fpr, ppv_func, f1_func, auc_func, cnf_matrix = calc_index(emberdf,__Label_use_name,export_fig)\n",
    "\n",
    "    clf_report = classification_report(emberdf.label,\n",
    "                                    emberdf.y_pred,\n",
    "                                    # labels=[*range(len(__Label_use_name))],\n",
    "                                    target_names=__Label_use_name,\n",
    "                                    output_dict=True,\n",
    "                                    zero_division = 0)\n",
    "\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(emberdf.label,\n",
    "                                    emberdf.y_pred,\n",
    "                                        labels=np.unique(y_true),\n",
    "                                        target_names=__Label_use_name,\n",
    "                                        output_dict=False,\n",
    "                                        zero_division = 0))\n",
    "\n",
    "  # plot cfs report\n",
    "    fig = sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True).get_figure()\n",
    "    plt.show()\n",
    "\n",
    "    if export_fig is not None:\n",
    "        fig.savefig(os.path.join(export_fig,'cfs_report.png'))\n",
    "\n",
    "  # print(\"=========================================================\")\n",
    "\n",
    "    return mcc, acc, tpr_func, fpr, ppv_func, f1_func, auc_func, clf_report, cnf_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_kinn(y_test,y_pred, encoder):\n",
    "    t0 = time.time()\n",
    "    if __MODE == \"Novelty_multi\":\n",
    "        __Label_use_name =  [\"-1\"] + list(encoder.classes_)\n",
    "        __Label_use_name =  [\"-1\"] + list(encoder.classes_)\n",
    "        print(\"DEBUG label\", __Label_use_name)\n",
    "    elif __MODE == \"1_Cls\":\n",
    "        __Label_use_name =  [\"Normal\"] + [\"Outlier\"]\n",
    "    else:\n",
    "        __Label_use_name =  list(encoder.classes_)\n",
    "\n",
    "    print(f\"__Label_use_name: {__Label_use_name}\")\n",
    "\n",
    "    mcc, acc, tpr_func, fpr, ppv_func, f1_func, auc_func, clf_report, cnf_matrix = Model_evaluating(y_test, y_pred, __Label_use_name)\n",
    "\n",
    "    # print(f\"Matthews corrcoef score: {mcc}\")\n",
    "\n",
    "\n",
    "    # print(\"Classification report\")\n",
    "    # # print(clf_report)\n",
    "    # print(classification_report(y_test, y_pred,\n",
    "    #                                     labels=np.unique(y_test),\n",
    "    #                                     target_names=__Label_use_name,\n",
    "    #                                     output_dict=False,\n",
    "    #                                     zero_division = 0))\n",
    "\n",
    "\n",
    "    return mcc, acc, tpr_func, fpr, ppv_func, f1_func, auc_func, clf_report, cnf_matrix,\n",
    "\n",
    "\n",
    "\n",
    "def Model_baseline_evaluating(y_true, y_pred, __Label_use_name, export_fig=None):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    y_pred = np.array(y_pred)\n",
    "    emberdf = pd.DataFrame({\n",
    "        'y_pred': y_pred.astype(int),\n",
    "        'label': y_true.astype(int)})\n",
    "    decoded_labels = __Label_use_name.inverse_transform(emberdf.label)\n",
    "    decoded_preds = __Label_use_name.inverse_transform(emberdf.y_pred)\n",
    "    labels = __Label_use_name.classes_\n",
    "\n",
    "    mcc, acc, tpr_func, fpr, ppv_func, f1_func, auc_func, cnf_matrix = calc_index(emberdf, __Label_use_name, export_fig)\n",
    "\n",
    "    clf_report = classification_report(decoded_labels,\n",
    "                                       decoded_preds,\n",
    "                                       labels=labels,\n",
    "                                       target_names=labels,\n",
    "                                       output_dict=True,\n",
    "                                       zero_division=0)\n",
    "\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(decoded_labels,\n",
    "                                decoded_preds,\n",
    "                                labels=labels,\n",
    "                                target_names=labels,\n",
    "                                output_dict=False,\n",
    "                                zero_division=0))\n",
    "\n",
    "    # Plot classification report\n",
    "    fig = sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)\n",
    "    plt.show()\n",
    "\n",
    "    if export_fig is not None:\n",
    "        fig.savefig(os.path.join(export_fig, 'cfs_report.png'))\n",
    "\n",
    "    return mcc, acc, tpr_func, fpr, ppv_func, f1_func, auc_func, clf_report, cnf_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6d6723a"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "b9a6ddf3"
   },
   "outputs": [],
   "source": [
    "def Running_Experiment_Novelty_Realistic(drop_cls, data):\n",
    "    ## ========================== Create Dataset ================================================\n",
    "    print(\"+\" + \"-\" * 48 + \"+\")\n",
    "    print(\"|\" + \" \" * 15 + \"CONFIG RUNNING INFO\" + \" \" * 14 + \"|\")\n",
    "    print(\"+\" + \"-\" * 48 + \"+\")\n",
    "\n",
    "    # Táº¡o má»™t danh sÃ¡ch cÃ¡c cáº·p (tÃªn, giÃ¡ trá»‹) Ä‘á»ƒ in ra\n",
    "    config_info = [\n",
    "        (\"Running Mode:\", __MODE),\n",
    "        (\"Drop class:\", drop_cls),\n",
    "        (\"R:\", __KNN),\n",
    "        (\"Kernel:\", __KERNEL),\n",
    "        (\"Type:\", __TYPE),\n",
    "        (\"Scaler Type:\", __SCALER)\n",
    "    ]\n",
    "\n",
    "    # XÃ¡c Ä‘á»‹nh chiá»u rá»™ng tá»‘i Ä‘a cá»§a tÃªn Ä‘á»ƒ cÄƒn chá»‰nh bá»‘ trÃ­\n",
    "    max_name_length = max(len(name) for name, _ in config_info)\n",
    "\n",
    "    # In ra tá»«ng cáº·p (tÃªn, giÃ¡ trá»‹) má»™t cÃ¡ch cÄƒn chá»‰nh\n",
    "    for name, value in config_info:\n",
    "        print(\"| \" + f\"{name.ljust(max_name_length)} {value}\".ljust(46) + \" |\")\n",
    "\n",
    "    print(\"+\" + \"-\" * 48 + \"+\")\n",
    "\n",
    "\n",
    "\n",
    "    X_train, y_train, X_test, y_test, classes_tmp, encoder = preprocess_data(drop_cls, data)\n",
    "\n",
    "    # return\n",
    "    print(\"========================== Running Proposal ==========================\")\n",
    "    res = []\n",
    "    # kinn_model = kINN(R=__KNN, kernel=__KERNEL)\n",
    "\n",
    "    # Khá»Ÿi táº¡o vÃ  fit mÃ´ hÃ¬nh\n",
    "    kinn_model = kINN(R = __KNN, kernel=__KERNEL, mode = __MODE)\n",
    "    t0 = time.time()\n",
    "    cluster_train, cluster_map = kinn_model.fit(X_train, y_train, False ,type= __TYPE)\n",
    "\n",
    "\n",
    "\n",
    "    no_cluster = len(np.unique(cluster_train))\n",
    "\n",
    "    t1 = time.time() - t0\n",
    "    print(\"Training time for kINN:\", t1)\n",
    "    print(\"Number of cluster return:\", len(np.unique(cluster_train)))\n",
    "    print(\"Number of cluster train:\", no_cluster)\n",
    "    print(\"No. sample each cluster:\", np.unique(cluster_map, return_counts = True))\n",
    "\n",
    "    if __MODE == \"Supervise\":\n",
    "        t0 = time.time()\n",
    "        y_pred = kinn_model.predict(X_test)\n",
    "        t2 = time.time() - t0\n",
    "        threshold = -1\n",
    "        ndr = -1\n",
    "        auc_n = -1\n",
    "\n",
    "    elif __MODE == \"1_Cls\":\n",
    "       #### Predictions\n",
    "        t0 = time.time()\n",
    "        y_pred, mcc, threshold = kinn_model.predict(X_test,y_test)\n",
    "        t2 = time.time() - t0\n",
    "        false_positive_rate, true_positive_rate, _ = roc_curve(y_test, y_pred)\n",
    "        auc_n = auc(false_positive_rate, true_positive_rate)\n",
    "        ndr = recall_score(y_test,y_pred,zero_division = 0)\n",
    "        print(f\"Novelty Detection Rate: {ndr}\")\n",
    "        print(\"AUC for Novelty score:\", auc_n)\n",
    "\n",
    "    else:\n",
    "        #### Predictions\n",
    "        t0 = time.time()\n",
    "        y_pred, mcc, threshold = kinn_model.predict(X_test, y_test)\n",
    "        t2 = time.time() - t0\n",
    "        y_test_bina = np.array([1 if y == -1 else 0 for y in y_test])\n",
    "        y_pred_bina = np.array([1 if y == -1 else 0 for y in y_pred])\n",
    "        false_positive_rate, true_positive_rate, _ = roc_curve(y_test_bina, y_pred_bina)\n",
    "        auc_n = auc(false_positive_rate, true_positive_rate)\n",
    "        ndr = recall_score(y_test_bina,y_pred_bina,zero_division = 0)\n",
    "        print(f\"Novelty Detection Rate: {ndr}\")\n",
    "        print(\"AUC for Novelty score:\", auc_n)\n",
    "\n",
    "    mcc, acc, tpr_func, fpr, ppv_func, f1_func, auc_func, clf_report, cnf_matrix = test_kinn(y_test, y_pred, encoder)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Testing time for KiNN:\", t2)\n",
    "    print(\"MCC score:\", mcc)\n",
    "\n",
    "    print(\"Confusion matrix\")\n",
    "    print(cnf_matrix)\n",
    "\n",
    "\n",
    "    res.append([drop_cls, mcc, ndr, auc_n, acc, tpr_func, fpr, ppv_func, f1_func, auc_func, clf_report, cnf_matrix, threshold, t1, t2])\n",
    "\n",
    "    print(\"*************************************** End Round ***************************************\")\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (77787, 55)\n",
      "y_train counts: (array([0, 1, 2, 3, 4]), array([25314,  9501, 11752, 17166, 14054]))\n",
      "X_test shape: (34522, 55)\n",
      "y_test counts: (array([0, 1, 2, 3, 4]), array([10849,  4286,  5302,  7744,  6341]))\n",
      "Begin Fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing class 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25314/25314 [00:01<00:00, 13951.54it/s]\n",
      "Processing class 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9501/9501 [00:00<00:00, 16658.20it/s]\n",
      "Processing class 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11752/11752 [00:00<00:00, 17223.96it/s]\n",
      "Processing class 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17166/17166 [00:00<00:00, 18973.87it/s]\n",
      "Processing class 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14054/14054 [00:00<00:00, 18809.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Fit\n",
      "Begin Predict\n"
     ]
    }
   ],
   "source": [
    "### Parameters ----------------------------------------------------------------\n",
    "__SEED = 42\n",
    "__KNN = 25\n",
    "__KERNEL = \"rbf\"\n",
    "__TYPE = \"density\"\n",
    "__TARGET = \"Label\"\n",
    "__SCALER = \"QuantileTransformer\"\n",
    "drop_cls = [\"*\"]\n",
    "__MODE = \"Supervise\"\n",
    "# Test\n",
    "X_train, y_train, X_test, y_test, classes_tmp, encoder = preprocess_data(drop_cls, df.copy())\n",
    "print(\"Begin Fit\")\n",
    "kinn_model = kINN(R = __KNN, kernel=__KERNEL, mode = __MODE)\n",
    "cluster_train, cluster_map = kinn_model.fit(X_train, y_train, False ,type= __TYPE)\n",
    "print(\"Done Fit\")\n",
    "print(\"Begin Predict\")\n",
    "# y_pred = kinn_model.predict(X_test)\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Fit scaler vÃ o dá»¯ liá»‡u huáº¥n luyá»‡n\n",
    "scaler = QuantileTransformer(output_distribution = \"normal\", random_state=42)\n",
    "X_train_scaled = scaler.fit(X_train)\n",
    "\n",
    "# LÆ°u scaler vÃ o tá»‡p\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(encoder, 'label_encoder.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_loaded = joblib.load('scaler.pkl')\n",
    "encoder_loaded = joblib.load('label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN2vpBC1xvi_"
   },
   "source": [
    "### Running Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"linear\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"MinMaxScaler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NJyWXCP8GiB6"
   },
   "outputs": [],
   "source": [
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "d6b5def2"
   },
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"rbf\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"MinMaxScaler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"poly\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"MinMaxScaler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"linear\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"StandardScaler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "NJyWXCP8GiB6"
   },
   "outputs": [],
   "source": [
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "d6b5def2"
   },
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"rbf\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"StandardScaler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"poly\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"StandardScaler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuantileTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"linear\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"QuantileTransformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "NJyWXCP8GiB6"
   },
   "outputs": [],
   "source": [
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "d6b5def2"
   },
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"rbf\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"QuantileTransformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"poly\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"QuantileTransformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"linear\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"Normalizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "NJyWXCP8GiB6"
   },
   "outputs": [],
   "source": [
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "d6b5def2"
   },
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"rbf\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"Normalizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"poly\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"Normalizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"sigmoid\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"MinMaxScaler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"sigmoid\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"StandardScaler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"sigmoid\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"QuantileTransformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "#         continue\n",
    "#     elif drop_cls == \"ARP\":\n",
    "#         continue\n",
    "#     # elif drop_cls == \"ICMP\":\n",
    "#     #     continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "#         continue\n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS M                                                                                 atrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Normalier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Parameters ----------------------------------------------------------------\n",
    "# __SEED = 42\n",
    "# __KNN = 5\n",
    "# __KERNEL = \"sigmoid\"\n",
    "# __TYPE = \"density\"\n",
    "# __TARGET = \"Label\"\n",
    "# __SCALER = \"Normalizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __res = []\n",
    "# __classes = np.sort(df[__TARGET].unique())\n",
    "# __range = np.concatenate(([\"*\"],[\"**\"] ,__classes), axis=0)\n",
    "\n",
    "\n",
    "# for drop_cls in __range:\n",
    "#     if drop_cls == \"0_normal\":\n",
    "#         continue\n",
    "#     elif drop_cls == \"*\":\n",
    "#         __MODE = \"Supervise\"\n",
    "#     elif drop_cls == \"**\":\n",
    "#         __MODE = \"1_Cls\"\n",
    "    \n",
    "# #     elif drop_cls == \"ARP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"ICMP\":\n",
    "# #         continue\n",
    "# #     elif drop_cls == \"TCP\":\n",
    "#   #      continue\n",
    "#     # elif drop_cls == \"UDP\":\n",
    "#     #     continue\n",
    "#     else:\n",
    "#         __MODE = \"Novelty_multi\"\n",
    "        \n",
    "#     drop_clss = [drop_cls]\n",
    "#     for seed in [42]:\n",
    "#         __SEED = seed\n",
    "#         res_tmp = Running_Experiment_Novelty_Realistic(drop_clss, df.copy())\n",
    "\n",
    "#         for x in res_tmp:\n",
    "#             __res.append([__KERNEL,__TYPE, __SEED] + x)\n",
    "\n",
    "\n",
    "\n",
    "# res_df = pd.DataFrame(__res, columns = [\"Kernel\", \"Type\",\"Seed\",\"Drop Cls\",\n",
    "#                                           \"MCC\", \"NDR\", \"AUC_N\", \"ACC\", \"TPR Macro\",\n",
    "#                                         \"FPR\", \"PPV Macro\", \"F1 Macro\", \"AUC\", \"CLS Report\",\n",
    "#                                         \"CFS Matrix\", \"Threshold\", \"Training time\", \"Test time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df\n",
    "# res_df.to_csv(f\"./res_novelty_tmp_{__KERNEL}_{__SCALER}.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FM1mL0RR5hRM"
   },
   "source": [
    "### Base Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qryoLnzKc3O4"
   },
   "source": [
    "#### Evaluate function def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "PrkrOPiFtlOd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "def Evaluate_Model(y_test, y_pred):\n",
    "  # acc = accuracy_score(y_test, y_pred)\n",
    "  mcc = matthews_corrcoef(y_test, y_pred)\n",
    "  f1 = f1_score(y_test, y_pred, average = \"macro\")\n",
    "  cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "  FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n",
    "  FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "  TP = np.diag(cnf_matrix)\n",
    "  TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "  acc = sum(TP+TN)/(sum(TP+FP+FN+TN)) *100.\n",
    "  tpr_func = recall_score(y_test,y_pred,average='macro', zero_division = 0) *100.\n",
    "  ppv_func = precision_score(y_test,y_pred,average='macro', zero_division = 0) *100.\n",
    "  f1_func = f1_score(y_test,y_pred,average='macro', zero_division = 0) *100.\n",
    "  mcc_func = matthews_corrcoef(y_test,y_pred)\n",
    "  FPR = sum(FP)/sum((FP+TN)) *100.\n",
    "\n",
    "  return acc, f1, cnf_matrix, tpr_func, ppv_func, f1_func, mcc_func, FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwDKaR5dc7so"
   },
   "source": [
    "#### Baseline Supervise models mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __Prameter_profile = {\n",
    "#     'RF': {\n",
    "#         'n_estimators': 5,  # Number of trees in the forest\n",
    "#         'max_depth': 5,    # Maximum depth of the tree. Default is None (nodes are expanded until all leaves contain less than min_samples_split samples)\n",
    "#         'min_samples_split': 2,  # Minimum number of samples required to split an internal node\n",
    "#         'min_samples_leaf': 2,   # Minimum number of samples required to be at a leaf node\n",
    "#         'bootstrap': True,       # Whether bootstrap samples are used when building trees\n",
    "#         'random_state': 42  ,     # Seed used by the random number generator\n",
    "        \n",
    "    \n",
    "#     },\n",
    "#     'LGBM': {\n",
    "#             \"boosting_type\": \"gbdt\",\n",
    "#             \"colsample_bynode\": 1,\n",
    "#             \"colsample_bytree\": 1,\n",
    "#             \"extra_trees\": True,\n",
    "#             \"learning_rate\": 0.03,\n",
    "#             \"l1_regularization\": 0.1,\n",
    "#             \"l2_regularization\": 10,\n",
    "#             \"max_depth\": 5,\n",
    "#             \"n_estimators\": 20,\n",
    "#             \"num_leaves\": 10,\n",
    "#             \"random_state\": 42,\n",
    "#             \"verbose\": -1,\n",
    "#             \"feature_fraction\": 0.9,\n",
    "#             \"bagging_fraction\": 0.8,\n",
    "#     },\n",
    "#     'SVC': {\n",
    "#         'C': 0.2,\n",
    "#         'kernel': \"linear\",\n",
    "#         'random_state': 42\n",
    "#     },\n",
    "#     'KNN': {\n",
    "#         'n_neighbors': 4,\n",
    "#         'leaf_size': 5,\n",
    "#         'p': 5,\n",
    "#         'algorithm': 'kd_tree'\n",
    "#     }\n",
    "\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "52f9472c"
   },
   "outputs": [],
   "source": [
    "def Model_evaluating(y_true, y_pred, __Label_use_name, export_fig = None):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    y_pred = np.array(y_pred)\n",
    "    emberdf = pd.DataFrame({\n",
    "        'y_pred': y_pred.astype(int),\n",
    "        'label': y_true.astype(int)})\n",
    "    # print(emberdf)\n",
    "    mcc, acc, tpr_func, fpr, ppv_func, f1_func, auc_func, cnf_matrix = calc_index(emberdf,__Label_use_name,export_fig)\n",
    "\n",
    "    clf_report = classification_report(emberdf.label,\n",
    "                                    emberdf.y_pred,\n",
    "                                    # labels=[*range(len(__Label_use_name))],\n",
    "                                    target_names=__Label_use_name,\n",
    "                                    output_dict=True,\n",
    "                                    zero_division = 0)\n",
    "\n",
    "    # print(\"Classification report:\")\n",
    "    # target_names = [str(label) for label in np.unique(y_true)]\n",
    "    # print(classification_report(emberdf.label,\n",
    "    #                                 emberdf.y_pred,\n",
    "    #                                     labels=np.unique(y_true),\n",
    "    #                                     target_names=__Label_use_name,\n",
    "    #                                     output_dict=False,\n",
    "    #                                     zero_division = 0))\n",
    "\n",
    "  # plot cfs report\n",
    "    fig = sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True).get_figure()\n",
    "    plt.show()\n",
    "\n",
    "    if export_fig is not None:\n",
    "        fig.savefig(os.path.join(export_fig,'cfs_report.png'))\n",
    "\n",
    "  # print(\"=========================================================\")\n",
    "\n",
    "    return mcc, acc, tpr_func, fpr, ppv_func, f1_func, auc_func, clf_report, cnf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "65aZphBFZul_"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "__SEED = 42\n",
    "__TARGET = \"Label\"\n",
    "#__SCALER = \"StandardScaler\"\n",
    "__MODE = \"Supervise\"\n",
    "\n",
    "\n",
    "def baseline_model(data):\n",
    "    start_time_training = time.time()\n",
    "\n",
    "    print(\"+\" + \"-\" * 48 + \"+\")\n",
    "    print(\"|\" + \" \" * 15 + \"CONFIG RUNNING INFO\" + \" \" * 14 + \"|\")\n",
    "    print(\"+\" + \"-\" * 48 + \"+\")\n",
    "\n",
    "    config_info = [\n",
    "        (\"Running Mode:\", __MODE),\n",
    "        (\"Scaler Type:\", __SCALER)\n",
    "    ]\n",
    "\n",
    "    max_name_length = max(len(name) for name, _ in config_info)\n",
    "\n",
    "    for name, value in config_info:\n",
    "        print(\"| \" + f\"{name.ljust(max_name_length)} {value}\".ljust(46) + \" |\")\n",
    "\n",
    "    print(\"+\" + \"-\" * 48 + \"+\")\n",
    "\n",
    "    drop_cls = \"*\"\n",
    "    X_train, y_train, X_test, y_test, classes_tmp, encoder = preprocess_data(drop_cls, data)\n",
    "\n",
    "    # Initialize an empty list to store results for each model\n",
    "    results_list = []\n",
    "\n",
    "    models = ['RandomForest', 'LGBM', 'SVM', 'KNN']\n",
    "    classifiers = [RandomForestClassifier(**__Prameter_profile['RF']),\n",
    "                   LGBMClassifier(**__Prameter_profile['LGBM']),\n",
    "                   SVC(**__Prameter_profile['SVC']),\n",
    "                   KNeighborsClassifier(**__Prameter_profile['KNN'])]\n",
    "\n",
    "    for model, clf in zip(models, classifiers):\n",
    "        start_time = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        train_time = end_time - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        y_pred = clf.predict(X_test)\n",
    "        end_time = time.time()\n",
    "        pred_time = end_time - start_time\n",
    "\n",
    "        mcc, acc, tpr_func, fpr, ppv_func, f1_func, auc_func, clf_report, cnf_matrix = Model_evaluating(y_test, y_pred, classes_tmp)\n",
    "\n",
    "        results_list.append({\n",
    "            'Model': model,\n",
    "            'Parameters': clf.get_params(),\n",
    "            'Accuracy': acc,\n",
    "            'MCC': mcc,\n",
    "            'Classification Report': classification_report(y_test, y_pred),\n",
    "            'Training Time (s)': train_time,\n",
    "            'Testing Time (s)': pred_time,\n",
    "            'PPV_macro': ppv_func,\n",
    "            'F1_score_macro': f1_func,\n",
    "            'TPR_macro': tpr_func,\n",
    "            'FPR': fpr,\n",
    "            'Confusion Matrix': cnf_matrix\n",
    "        })\n",
    "\n",
    "    df_results = pd.DataFrame(results_list)\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running baseline_model with scaler: StandardScaler\n",
      "+------------------------------------------------+\n",
      "|               CONFIG RUNNING INFO              |\n",
      "+------------------------------------------------+\n",
      "| Running Mode: Supervise                        |\n",
      "| Scaler Type:  StandardScaler                   |\n",
      "+------------------------------------------------+\n",
      "X_train shape: (77787, 55)\n",
      "y_train counts: (array([0, 1, 2, 3, 4]), array([25314,  9501, 11752, 17166, 14054]))\n",
      "X_test shape: (34522, 55)\n",
      "y_test counts: (array([0, 1, 2, 3, 4]), array([10849,  4286,  5302,  7744,  6341]))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__Prameter_profile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning baseline_model with scaler: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscaler_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     __SCALER \u001b[38;5;241m=\u001b[39m scaler_name  \u001b[38;5;66;03m# Thiáº¿t láº­p giÃ¡ trá»‹ cá»§a __SCALER\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mbaseline_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Cháº¡y baseline_model vá»›i scaler hiá»‡n táº¡i\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mappend(results)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Káº¿t há»£p táº¥t cáº£ cÃ¡c káº¿t quáº£ vÃ o má»™t DataFrame\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[69], line 42\u001b[0m, in \u001b[0;36mbaseline_model\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     39\u001b[0m results_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     41\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLGBM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKNN\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 42\u001b[0m classifiers \u001b[38;5;241m=\u001b[39m [RandomForestClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43m__Prameter_profile\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     43\u001b[0m                LGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__Prameter_profile[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLGBM\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     44\u001b[0m                SVC(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__Prameter_profile[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVC\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     45\u001b[0m                KNeighborsClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__Prameter_profile[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKNN\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model, clf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(models, classifiers):\n\u001b[1;32m     48\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mNameError\u001b[0m: name '__Prameter_profile' is not defined"
     ]
    }
   ],
   "source": [
    "# Danh sÃ¡ch tÃªn cá»§a cÃ¡c scaler cáº§n thá»­\n",
    "scaler_names = [\"StandardScaler\", \"MinMaxScaler\", \"QuantileTransformer\", \"Normalizer\"]\n",
    "\n",
    "# Káº¿t quáº£ sáº½ Ä‘Æ°á»£c lÆ°u vÃ o má»™t danh sÃ¡ch\n",
    "all_results = []\n",
    "\n",
    "# Láº·p qua tá»«ng tÃªn scaler vÃ  cháº¡y baseline_model\n",
    "for scaler_name in scaler_names:\n",
    "    print(f\"Running baseline_model with scaler: {scaler_name}\")\n",
    "    __SCALER = scaler_name  # Thiáº¿t láº­p giÃ¡ trá»‹ cá»§a __SCALER\n",
    "    results = baseline_model(df.copy())  # Cháº¡y baseline_model vá»›i scaler hiá»‡n táº¡i\n",
    "    all_results.append(results)\n",
    "\n",
    "# Káº¿t há»£p táº¥t cáº£ cÃ¡c káº¿t quáº£ vÃ o má»™t DataFrame\n",
    "final_results = pd.concat(all_results, keys=scaler_names, names=[\"Scaler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_results.to_csv(\"supervised.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6R5AmUvdB5I"
   },
   "source": [
    "#### Baseline One Class models mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "269e15b6"
   },
   "outputs": [],
   "source": [
    "__MODE = \"1_Cls\"\n",
    "__SEED = 42\n",
    "__SCALER = \"QuantileTransformer\"\n",
    "\n",
    "def baseline_model_1Cls(data):\n",
    "    drop_cls = \"*\"\n",
    "    X_train, y_train, X_test, y_test, classes_tmp, encoder = preprocess_data(drop_cls, data)\n",
    "\n",
    "\n",
    "    iforest_clf = IForest()\n",
    "    iforest_clf.fit(X_train, y_train)\n",
    "\n",
    "    iforest_pred = iforest_clf.predict(X_test)\n",
    "    iforest_acc, iforest_f1, iforest_cnf_matrix, iforest_tpr_func, iforest_ppv_func, iforest_f1_func, iforest_mcc_func, iforest_FPR = Evaluate_Model(y_test, iforest_pred)\n",
    "\n",
    "\n",
    "\n",
    "    lof_clf = LOF()\n",
    "    lof_clf.fit(X_train, y_train)\n",
    "    lof_pred = lof_clf.predict(X_test)\n",
    "    lof_acc, lof_f1, lof_cnf_matrix, lof_tpr_func, lof_ppv_func, lof_f1_func, lof_mcc_func, lof_FPR = Evaluate_Model(y_test, lof_pred)\n",
    "\n",
    "\n",
    "    ocsvm_clf = OCSVM()\n",
    "    ocsvm_clf.fit(X_train, y_train)\n",
    "    ocsvm_pred = ocsvm_clf.predict(X_test)\n",
    "    ocsvm_acc, ocsvm_f1, ocsvm_cnf_matrix, ocsvm_tpr_func, ocsvm_ppv_func, ocsvm_f1_func, ocsvm_mcc_func, ocsvm_FPR = Evaluate_Model(y_test, ocsvm_pred)\n",
    "\n",
    "\n",
    "    abod_clf = ABOD(n_neighbors=3)\n",
    "    abod_clf.fit(X_train, y_train)\n",
    "    abod_pred = abod_clf.predict(X_test)\n",
    "    abod_acc, abod_f1, abod_cnf_matrix, abod_tpr_func, abod_ppv_func, abod_f1_func, abod_mcc_func, abod_FPR = Evaluate_Model(y_test, abod_pred)\n",
    "\n",
    "    inne_clf = INNE()\n",
    "    inne_clf.fit(X_train, y_train)\n",
    "    inne_pred = inne_clf.predict(X_test)\n",
    "    inne_acc, inne_f1, inne_cnf_matrix, inne_tpr_func, inne_ppv_func, inne_f1_func, inne_mcc_func, inne_FPR = Evaluate_Model(y_test, inne_pred)\n",
    "\n",
    "    models = ['IForest', 'LOF', 'OCSVM', 'ABOD', 'INNE']\n",
    "    parameters = [iforest_clf.get_params(), lof_clf.get_params(), ocsvm_clf.get_params(), abod_clf.get_params(), inne_clf.get_params()]\n",
    "    accuracies = [iforest_acc, lof_acc, ocsvm_acc, abod_acc, inne_acc]\n",
    "    mccs = [iforest_mcc_func, lof_mcc_func, ocsvm_mcc_func, abod_mcc_func, inne_mcc_func]\n",
    "    f1_scores = [iforest_f1, lof_f1, ocsvm_f1, abod_f1, inne_f1]\n",
    "    tprs = [iforest_tpr_func, lof_tpr_func, ocsvm_tpr_func, abod_tpr_func, inne_tpr_func]\n",
    "    fprs = [iforest_FPR, lof_FPR, ocsvm_FPR, abod_FPR, inne_FPR]\n",
    "    ppvs = [iforest_ppv_func, lof_ppv_func, ocsvm_ppv_func, abod_ppv_func, inne_ppv_func]\n",
    "    matrix = [iforest_cnf_matrix, lof_cnf_matrix, ocsvm_cnf_matrix, abod_cnf_matrix, inne_cnf_matrix]\n",
    "\n",
    "    results = {\n",
    "        'Model': models,\n",
    "        'Parameters': parameters,\n",
    "        'Accuracy': accuracies,\n",
    "        'MCC': mccs,\n",
    "        'F1 Score': f1_scores,\n",
    "        'TPR': tprs,\n",
    "        'FPR': fprs,\n",
    "        'PPV': ppvs,\n",
    "        'Confusion-matrix': matrix\n",
    "    }\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    return df_results\n",
    "\n",
    "results = baseline_model_1Cls(df.copy())\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(f\"One_class_customdata_{__SCALER}_fix.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 4558002,
     "sourceId": 7787318,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4689630,
     "sourceId": 8536977,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
